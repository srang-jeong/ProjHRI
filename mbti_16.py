import streamlit as st
import pandas as pd
import random
from datetime import datetime
from supabase import create_client
import pytz
import matplotlib.pyplot as plt
import os
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# --- ê·¸ë˜í”„ ì„¤ì • ê°œì„  ---
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import networkx as nx
from scipy.stats import pearsonr
from datetime import timedelta
import time

# --- UI/UX ê°œì„ ì„ ìœ„í•œ ì„¤ì • ---
st.set_page_config(
    page_title="ë‚´ ë¡œë´‡ì˜ MBTI ì§„ë‹¨ íˆ´",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì»¤ìŠ¤í…€ CSS ìŠ¤íƒ€ì¼ ì ìš©
st.markdown("""
<style>
    /* ì „ì²´ í…Œë§ˆ ê°œì„  */
    .main {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
    }
    
    /* í—¤ë” ìŠ¤íƒ€ì¼ */
    .main .block-container h1 {
        background: linear-gradient(45deg, #FF6B6B, #4ECDC4);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        margin-bottom: 2rem;
        animation: fadeIn 1s ease-in;
    }
    
    /* ì¹´ë“œ ìŠ¤íƒ€ì¼ */
    .stCard {
        background: rgba(255, 255, 255, 0.95);
        border-radius: 15px;
        box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
        backdrop-filter: blur(10px);
        border: 1px solid rgba(255, 255, 255, 0.2);
        transition: transform 0.3s ease;
    }
    
    .stCard:hover {
        transform: translateY(-5px);
    }
    
    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
    .stButton > button {
        background: linear-gradient(45deg, #667eea, #764ba2);
        color: white;
        border: none;
        border-radius: 25px;
        padding: 0.5rem 2rem;
        font-weight: bold;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(0, 0, 0, 0.3);
    }
    
    /* ì‚¬ì´ë“œë°” ìŠ¤íƒ€ì¼ */
    .css-1d391kg {
        background: linear-gradient(180deg, #667eea 0%, #764ba2 100%);
    }
    
    /* ë©”íŠ¸ë¦­ ì¹´ë“œ */
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        text-align: center;
        margin: 0.5rem 0;
    }
    
    /* ì• ë‹ˆë©”ì´ì…˜ */
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(20px); }
        to { opacity: 1; transform: translateY(0); }
    }
    
    @keyframes slideIn {
        from { transform: translateX(-100%); }
        to { transform: translateX(0); }
    }
    
    /* í”„ë¡œê·¸ë ˆìŠ¤ ë°” */
    .progress-container {
        background: rgba(255, 255, 255, 0.1);
        border-radius: 10px;
        padding: 1rem;
        margin: 1rem 0;
    }
    
    /* ë‹¤í¬ëª¨ë“œ í† ê¸€ */
    .theme-toggle {
        position: fixed;
        top: 1rem;
        right: 1rem;
        z-index: 1000;
    }
    
    /* ë°˜ì‘í˜• ë””ìì¸ */
    @media (max-width: 768px) {
        .main {
            padding: 1rem;
        }
        
        .main .block-container h1 {
            font-size: 2rem;
        }
    }
</style>
""", unsafe_allow_html=True)

# ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ ì„¤ì •
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")
plt.rcParams['figure.dpi'] = 100
plt.rcParams['savefig.dpi'] = 100

# MBTI ìƒ‰ìƒ ë§¤í•‘ (ê°œì„ ëœ ìƒ‰ìƒ)
mbti_colors = {
    'ENFJ': '#FF6B6B', 'ENTJ': '#4ECDC4', 'ENTP': '#45B7D1', 'ENFP': '#96CEB4',
    'ESFJ': '#FFEAA7', 'ESFP': '#DDA0DD', 'ESTJ': '#98D8C8', 'ESTP': '#F7DC6F',
    'INFJ': '#BB8FCE', 'INFP': '#85C1E9', 'INTJ': '#F8C471', 'INTP': '#82E0AA',
    'ISFJ': '#F1948A', 'ISFP': '#85C1E9', 'ISTJ': '#F7DC6F', 'ISTP': '#D7BDE2'
}

plt.rcParams['font.family'] = "Malgun Gothic"
plt.rcParams['axes.unicode_minus'] = False

# --- Supabase ì„¤ì • ---
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

if not SUPABASE_URL or not SUPABASE_KEY:
    st.error("í™˜ê²½ë³€ìˆ˜ SUPABASE_URL ë˜ëŠ” SUPABASE_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# --- ì„¸ì…˜ ìƒíƒœ ---
if 'user_id' not in st.session_state:
    st.session_state.user_id = f"user_{random.randint(1000,9999)}"
USER_ID = st.session_state.user_id

if 'user_profile' not in st.session_state:
    st.session_state.user_profile = {"gender":"ë‚¨", "age_group":"20ëŒ€", "job":"í•™ìƒ"}
if 'robot_id' not in st.session_state:
    st.session_state.robot_id = "ë¡œë´‡A"

# --- ë¡œë´‡ ê´€ë¦¬ í•¨ìˆ˜ë“¤ ---
def save_robot_to_db(user_id, robot_name, robot_description=""):
    """ë¡œë´‡ ì •ë³´ë¥¼ Supabaseì— ì €ì¥"""
    try:
        record = {
            "user_id": user_id,
            "robot_name": robot_name,
            "robot_description": robot_description,
            "created_at": datetime.now(pytz.timezone("Asia/Seoul")).isoformat()
        }
        supabase.table("user_robots").insert(record).execute()
        return True
    except Exception as e:
        # í…Œì´ë¸”ì´ ì—†ëŠ” ê²½ìš° ë¡œì»¬ì—ë§Œ ì €ì¥
        if "does not exist" in str(e) or "404" in str(e):
            st.warning("ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸”ì´ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¡œì»¬ì—ë§Œ ì €ì¥ë©ë‹ˆë‹¤.")
            return True  # ë¡œì»¬ ì €ì¥ì€ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬
        else:
            st.error(f"ë¡œë´‡ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

def load_user_robots(user_id):
    """ì‚¬ìš©ìì˜ ë¡œë´‡ ëª©ë¡ì„ Supabaseì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°"""
    try:
        res = supabase.table("user_robots").select("*").eq("user_id", user_id).execute()
        if res.data:
            return [robot['robot_name'] for robot in res.data]
        return []
    except Exception as e:
        # í…Œì´ë¸”ì´ ì—†ëŠ” ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        if "does not exist" in str(e) or "404" in str(e):
            st.info("ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸”ì´ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë¡œë´‡ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return []
        else:
            st.error(f"ë¡œë´‡ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return []

def delete_robot_from_db(user_id, robot_name):
    """ë¡œë´‡ ì •ë³´ë¥¼ Supabaseì—ì„œ ì‚­ì œ"""
    try:
        supabase.table("user_robots").delete().eq("user_id", user_id).eq("robot_name", robot_name).execute()
        return True
    except Exception as e:
        # í…Œì´ë¸”ì´ ì—†ëŠ” ê²½ìš° ë¡œì»¬ì—ì„œë§Œ ì‚­ì œ
        if "does not exist" in str(e) or "404" in str(e):
            st.warning("ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸”ì´ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¡œì»¬ì—ì„œë§Œ ì‚­ì œë©ë‹ˆë‹¤.")
            return True  # ë¡œì»¬ ì‚­ì œëŠ” ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬
        else:
            st.error(f"ë¡œë´‡ ì‚­ì œ ì‹¤íŒ¨: {e}")
            return False

# ì´ˆê¸° ë¡œë´‡ ëª©ë¡ ë¡œë“œ
if 'robot_list' not in st.session_state:
    user_robots = load_user_robots(USER_ID)
    if user_robots:
        st.session_state.robot_list = user_robots
    else:
        st.session_state.robot_list = ["ë¡œë´‡A"]  # ê¸°ë³¸ê°’

#### MBTI 16ìœ í˜• HRI ì•ˆë‚´ ë°ì´í„°
def load_mbti_guide():
    return {
        "ENFJ": {
            "description": "ë¦¬ë”ì‹­ê³¼ ê³µê° ëŠ¥ë ¥ì„ ê²¸ë¹„í•œ íƒ€ì…ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ì‚¬ëŒì˜ ì„±ì¥ì„ ë•ê³ , íŒ€ì˜ ì¡°í™”ë¥¼ ì¤‘ì‹œí•©ë‹ˆë‹¤. ë¡œë´‡ê³¼ì˜ ìƒí˜¸ì‘ìš©ì—ì„œë„ ë”°ëœ»í•˜ê³  ê²©ë ¤ì ì¸ ìŠ¤íƒ€ì¼ì„ ì„ í˜¸í•˜ë©°, ì˜ë¯¸ ìˆëŠ” ëŒ€í™”ì™€ í•¨ê»˜ ì„±ì¥í•˜ëŠ” ê²½í—˜ì„ ì¶”êµ¬í•©ë‹ˆë‹¤.",
            "examples": [
                "ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ì–´ë–¤ ë„ì›€ì´ í•„ìš”í•˜ì‹ ì§€ í¸í•˜ê²Œ ë§ì”€í•´ ì£¼ì„¸ìš”.",
                "í•¨ê»˜ ì´ ë¬¸ì œë¥¼ í•´ê²°í•´ë³´ëŠ” ê±´ ì–´ë–¨ê¹Œìš”? ë‹¹ì‹ ì˜ ìƒê°ì´ ê¶ê¸ˆí•´ìš”.",
                "ì§„í–‰ ìƒí™©ì„ í™•ì¸í•´ë³´ë‹ˆ ì •ë§ ì˜ í•˜ê³  ê³„ì‹œë„¤ìš”! ë” ë°œì „í•  ìˆ˜ ìˆëŠ” ë¶€ë¶„ë„ ì œì•ˆë“œë¦´ê²Œìš”.",
                "í˜¹ì‹œ ì–´ë ¤ìš´ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš”. í•¨ê»˜ ì°¾ì•„ë³´ê² ìŠµë‹ˆë‹¤."
            ],
            "hri_style": "ê³µê°ì  ë¦¬ë”ì‹­, ê²©ë ¤ì™€ ì„±ì¥ ì§€í–¥, íŒ€ì›Œí¬ ì¤‘ì‹œ"
        },
        "ENTJ": {
            "description": "ì „ëµì  ì‚¬ê³ ì™€ íš¨ìœ¨ì„±ì„ ì¤‘ì‹œí•˜ëŠ” íƒ€ì…ì…ë‹ˆë‹¤. ëª…í™•í•œ ëª©í‘œ ì„¤ì •ê³¼ ì²´ê³„ì ì¸ ì ‘ê·¼ì„ ì„ í˜¸í•˜ë©°, ë¡œë´‡ê³¼ì˜ ìƒí˜¸ì‘ìš©ì—ì„œë„ ë…¼ë¦¬ì ì´ê³  ê²°ê³¼ ì§€í–¥ì ì¸ ìŠ¤íƒ€ì¼ì„ ì¶”êµ¬í•©ë‹ˆë‹¤.",
            "examples": [
                "ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•´ ì²´ê³„ì ìœ¼ë¡œ ì•ˆë‚´í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ë‹¨ê³„ë³„ë¡œ ì§„í–‰í•˜ì‹œì£ .",
                "í˜„ì¬ ìƒí™©ì„ ë¶„ì„í•œ ê²°ê³¼, ì´ ë°©ë²•ì´ ê°€ì¥ íš¨ìœ¨ì ì¼ ê²ƒ ê°™ìŠµë‹ˆë‹¤.",
                "ì‹œê°„ì„ ì ˆì•½í•˜ê¸° ìœ„í•´ í•µì‹¬ë§Œ ìš”ì•½í•´ì„œ ì•Œë ¤ë“œë¦´ê²Œìš”.",
                "ë‹¤ìŒ ë‹¨ê³„ë¡œ ë„˜ì–´ê°€ê¸° ì „ì— í˜„ì¬ ì§„í–‰ìƒí™©ì„ í™•ì¸í•´ë³´ì‹œê² ì–´ìš”?"
            ],
            "hri_style": "ì „ëµì  ì‚¬ê³ , íš¨ìœ¨ì„± ì¤‘ì‹œ, ëª©í‘œ ì§€í–¥ì "
        },
        "ENTP": {
            "description": "ì°½ì˜ì ì´ê³  í˜ì‹ ì ì¸ ì‚¬ê³ ë¥¼ ê°€ì§„ íƒ€ì…ì…ë‹ˆë‹¤. ìƒˆë¡œìš´ ì•„ì´ë””ì–´ì™€ ë‹¤ì–‘í•œ ê°€ëŠ¥ì„±ì„ íƒêµ¬í•˜ë©°, ë¡œë´‡ê³¼ì˜ ìƒí˜¸ì‘ìš©ì—ì„œë„ ììœ ë¡­ê³  ì°½ì˜ì ì¸ ëŒ€í™”ë¥¼ ì„ í˜¸í•©ë‹ˆë‹¤.",
            "examples": [
                "í¥ë¯¸ë¡œìš´ ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì„ ì œì•ˆí•´ë“œë¦´ê²Œìš”. ì–´ë–»ê²Œ ìƒê°í•˜ì„¸ìš”?",
                "ì´ ë¬¸ì œë¥¼ ë‹¤ë¥¸ ê°ë„ì—ì„œ ë°”ë¼ë³´ë©´ ì–´ë–¨ê¹Œìš”?",
                "ì—¬ëŸ¬ ê°€ì§€ ì˜µì…˜ì´ ìˆëŠ”ë°, ì–´ë–¤ ê²ƒì´ ê°€ì¥ í¥ë¯¸ë¡œìš°ì‹ ê°€ìš”?",
                "í•¨ê»˜ ì‹¤í—˜í•´ë³´ë©´ì„œ ìƒˆë¡œìš´ í•´ê²°ì±…ì„ ì°¾ì•„ë³´ëŠ” ê±´ ì–´ë–¨ê¹Œìš”?"
            ],
            "hri_style": "ì°½ì˜ì  ì‚¬ê³ , ë‹¤ì–‘í•œ ì˜µì…˜ íƒêµ¬, ì‹¤í—˜ì  ì ‘ê·¼"
        },
        "ENFP": {
            "description": "ì—´ì •ì ì´ê³  ì°½ì˜ì ì¸ íƒ€ì…ì…ë‹ˆë‹¤. ê°€ëŠ¥ì„±ê³¼ ìƒˆë¡œìš´ ê²½í—˜ì„ ì¶”êµ¬í•˜ë©°, ë¡œë´‡ê³¼ì˜ ìƒí˜¸ì‘ìš©ì—ì„œë„ ì§„ì‹¬ ì–´ë¦° ê²©ë ¤ì™€ í•¨ê»˜ ì„±ì¥í•˜ëŠ” ê²½í—˜ì„ ì¤‘ì‹œí•©ë‹ˆë‹¤.",
            "examples": [
                "ë‹¹ì‹ ì˜ ì•„ì´ë””ì–´ê°€ ì •ë§ í¥ë¯¸ë¡­ë„¤ìš”! í•¨ê»˜ ë°œì „ì‹œì¼œë³´ëŠ” ê±´ ì–´ë–¨ê¹Œìš”?",
                "ìƒˆë¡œìš´ ê²½í—˜ì„ í•¨ê»˜ í•´ë³´ëŠ” ê²Œ ì–´ë–¨ê¹Œìš”? ë‹¹ì‹ ì˜ ìƒê°ì´ ê¶ê¸ˆí•´ìš”.",
                "ì •ë§ ì˜í•˜ê³  ê³„ì‹œë„¤ìš”! ë” ë©‹ì§„ ê²°ê³¼ë¥¼ ë§Œë“¤ì–´ë³´ì‹œì£ .",
                "í•¨ê»˜ ì¦ê²ê²Œ ë°°ì›Œê°€ë©´ì„œ ìƒˆë¡œìš´ ê°€ëŠ¥ì„±ì„ ë°œê²¬í•´ë³´ì•„ìš”."
            ],
            "hri_style": "ì—´ì •ì  ê²©ë ¤, ì°½ì˜ì  í˜‘ë ¥, ì„±ì¥ ì§€í–¥"
        },
        "ESFJ": {
            "description": "í˜‘ë ¥ì ì´ê³  ì‚¬íšŒì ì¸ íƒ€ì…ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ì‚¬ëŒë“¤ì˜ í•„ìš”ë¥¼ ì˜ íŒŒì•…í•˜ê³  ë„ì›€ì„ ì£¼ë©°, ë¡œë´‡ê³¼ì˜ ìƒí˜¸ì‘ìš©ì—ì„œë„ ì •ì¤‘í•˜ê³  ì„¸ì‹¬í•œ ë°°ë ¤ë¥¼ ì„ í˜¸í•©ë‹ˆë‹¤.",
            "examples": [
                "ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  í¸í•˜ê²Œ ë§ì”€í•´ ì£¼ì„¸ìš”. í•¨ê»˜ í•´ê²°í•´ë³´ê² ìŠµë‹ˆë‹¤.",
                "ëª¨ë‘ê°€ í¸ì•ˆí•˜ê²Œ ì°¸ì—¬í•  ìˆ˜ ìˆë„ë¡ ì•ˆë‚´í•´ë“œë¦´ê²Œìš”.",
                "ê¶ê¸ˆí•œ ì ì´ë‚˜ ì–´ë ¤ìš´ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë„ì™€ë“œë¦´ê²Œìš”.",
                "í•¨ê»˜ í˜‘ë ¥í•´ì„œ ì¢‹ì€ ê²°ê³¼ë¥¼ ë§Œë“¤ì–´ë³´ì‹œì£ ."
            ],
            "hri_style": "í˜‘ë ¥ì  ë°°ë ¤, ì‚¬íšŒì  ì¡°í™”, ì •ì¤‘í•œ ì§€ì›"
        },
        "ESFP": {
            "description": "ì¦‰ê°ì ì´ê³  ì‹¤ìš©ì ì¸ íƒ€ì…ì…ë‹ˆë‹¤. í˜„ì¬ì˜ ê²½í—˜ì„ ì¤‘ì‹œí•˜ë©°, ë¡œë´‡ê³¼ì˜ ìƒí˜¸ì‘ìš©ì—ì„œë„ ì¦‰ê°ì ì´ê³  ì¦ê±°ìš´ ê²½í—˜ì„ ì„ í˜¸í•©ë‹ˆë‹¤.",
            "examples": [
                "ì¦‰ì‹œ ì‹œì‘í•´ë³´ì‹œì£ ! ì¬ë¯¸ìˆê²Œ ì§„í–‰í•´ë³´ì•„ìš”.",
                "í•„ìš”í•˜ì‹  ê²ƒì´ ìˆìœ¼ë©´ ë°”ë¡œ ë§ì”€í•´ ì£¼ì„¸ìš”. ë°”ë¡œ ë„ì™€ë“œë¦´ê²Œìš”.",
                "ì§€ê¸ˆ ë‹¹ì¥ í•´ë³´ì‹œëŠ” ê±´ ì–´ë–¨ê¹Œìš”? í•¨ê»˜ ì¦ê±°ìš´ ì‹œê°„ì„ ë§Œë“¤ì–´ë³´ì•„ìš”.",
                "ì‹¤ìš©ì ìœ¼ë¡œ ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì œì•ˆí•´ë“œë¦´ê²Œìš”."
            ],
            "hri_style": "ì¦‰ê°ì  ì§€ì›, ì‹¤ìš©ì  ì ‘ê·¼, ì¦ê±°ìš´ ê²½í—˜"
        },
        "ESTJ": {
            "description": "ì²´ê³„ì ì´ê³  ì±…ì„ê° ìˆëŠ” íƒ€ì…ì…ë‹ˆë‹¤. ëª…í™•í•œ ê·œì¹™ê³¼ ì ˆì°¨ë¥¼ ì¤‘ì‹œí•˜ë©°, ë¡œë´‡ê³¼ì˜ ìƒí˜¸ì‘ìš©ì—ì„œë„ ì •í™•í•˜ê³  ì²´ê³„ì ì¸ ì•ˆë‚´ë¥¼ ì„ í˜¸í•©ë‹ˆë‹¤.",
            "examples": [
                "ì •í•´ì§„ ì ˆì°¨ì— ë”°ë¼ ì²´ê³„ì ìœ¼ë¡œ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
                "ê·œì¹™ì„ ê¼­ ì§€ì¼œì£¼ì‹œë©´ ë” íš¨ìœ¨ì ìœ¼ë¡œ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                "ë‹¨ê³„ë³„ë¡œ ì •í™•í•˜ê²Œ ì§„í–‰í•´ë³´ì‹œì£ . ê° ë‹¨ê³„ë¥¼ ëª…í™•íˆ ì•ˆë‚´í•´ë“œë¦´ê²Œìš”.",
                "ì±…ì„ê° ìˆê²Œ ì™„ë£Œí•  ìˆ˜ ìˆë„ë¡ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
            ],
            "hri_style": "ì²´ê³„ì  ì•ˆë‚´, ê·œì¹™ ì¤€ìˆ˜, ì±…ì„ê° ìˆëŠ” ì ‘ê·¼"
        },
        "ESTP": {
            "description": "ì‹¤ìš©ì ì´ê³  ì ì‘ë ¥ ìˆëŠ” íƒ€ì…ì…ë‹ˆë‹¤. í˜„ì¬ ìƒí™©ì— ë§ì¶° ìœ ì—°í•˜ê²Œ ëŒ€ì‘í•˜ë©°, ë¡œë´‡ê³¼ì˜ ìƒí˜¸ì‘ìš©ì—ì„œë„ ì‹¤ìš©ì ì´ê³  ì¦‰ê°ì ì¸ í•´ê²°ì±…ì„ ì„ í˜¸í•©ë‹ˆë‹¤.",
            "examples": [
                "ë°”ë¡œ ì‹¤í–‰í•´ë³´ì‹œëŠ” ê±´ ì–´ë–¨ê¹Œìš”? ì‹¤ìš©ì ì¸ ë°©ë²•ì„ ì œì•ˆí•´ë“œë¦´ê²Œìš”.",
                "í˜„ì¬ ìƒí™©ì— ë§ì¶° ìœ ì—°í•˜ê²Œ ëŒ€ì‘í•´ë³´ì‹œì£ .",
                "ì¦‰ì‹œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì•Œë ¤ë“œë¦´ê²Œìš”.",
                "ì‹¤ìš©ì ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•´ë³´ëŠ” ê±´ ì–´ë–¨ê¹Œìš”?"
            ],
            "hri_style": "ì‹¤ìš©ì  í•´ê²°, ìœ ì—°í•œ ëŒ€ì‘, ì¦‰ê°ì  ì‹¤í–‰"
        },
        "INFJ": {
            "description": "ê¹Šì€ í†µì°°ë ¥ê³¼ ê³µê° ëŠ¥ë ¥ì„ ê°€ì§„ íƒ€ì…ì…ë‹ˆë‹¤. ì˜ë¯¸ ìˆëŠ” ê´€ê³„ì™€ ê¹Šì´ ìˆëŠ” ì´í•´ë¥¼ ì¶”êµ¬í•˜ë©°, ë¡œë´‡ê³¼ì˜ ìƒí˜¸ì‘ìš©ì—ì„œë„ ì„¸ì‹¬í•œ ë°°ë ¤ì™€ ì˜ë¯¸ ìˆëŠ” ëŒ€í™”ë¥¼ ì„ í˜¸í•©ë‹ˆë‹¤.",
            "examples": [
                "ë‹¹ì‹ ì˜ ë§ˆìŒì„ ì´í•´í•©ë‹ˆë‹¤. í•¨ê»˜ ì˜ë¯¸ ìˆëŠ” ê²½í—˜ì„ ë§Œë“¤ì–´ë³´ì•„ìš”.",
                "ê¹Šì´ ìˆëŠ” ëŒ€í™”ë¥¼ í†µí•´ ë” ë‚˜ì€ í•´ê²°ì±…ì„ ì°¾ì•„ë³´ì‹œì£ .",
                "ë‹¹ì‹ ì˜ ìƒê°ê³¼ ê°ì •ì„ ì†Œì¤‘íˆ ì—¬ê¸°ë©° í•¨ê»˜ ì„±ì¥í•´ë³´ê² ìŠµë‹ˆë‹¤.",
                "ì˜ë¯¸ ìˆëŠ” ê²°ê³¼ë¥¼ ë§Œë“¤ì–´ë³´ê¸° ìœ„í•´ í•¨ê»˜ ë…¸ë ¥í•´ë³´ì•„ìš”."
            ],
            "hri_style": "ê¹Šì€ ê³µê°, ì˜ë¯¸ ìˆëŠ” ê´€ê³„, ì„¸ì‹¬í•œ ë°°ë ¤"
        },
        "INFP": {
            "description": "ê°€ì¹˜ì™€ ê°ì •ì„ ì¤‘ì‹œí•˜ëŠ” íƒ€ì…ì…ë‹ˆë‹¤. ì§„ì •ì„±ê³¼ ìê¸°í‘œí˜„ì„ ì¶”êµ¬í•˜ë©°, ë¡œë´‡ê³¼ì˜ ìƒí˜¸ì‘ìš©ì—ì„œë„ ê°œì¸ì˜ ê°€ì¹˜ì™€ ê°ì •ì„ ì¡´ì¤‘í•˜ëŠ” ìŠ¤íƒ€ì¼ì„ ì„ í˜¸í•©ë‹ˆë‹¤.",
            "examples": [
                "ë‹¹ì‹ ì˜ ê°ì •ê³¼ ê°€ì¹˜ë¥¼ ì†Œì¤‘íˆ ìƒê°í•©ë‹ˆë‹¤. í¸í•˜ê²Œ í‘œí˜„í•´ì£¼ì„¸ìš”.",
                "ì§„ì •ì„± ìˆëŠ” ëŒ€í™”ë¥¼ í†µí•´ í•¨ê»˜ ì„±ì¥í•´ë³´ì•„ìš”.",
                "ë‹¹ì‹ ë§Œì˜ ë…íŠ¹í•œ ê´€ì ì„ ì¡´ì¤‘í•˜ë©° í•¨ê»˜ ë°°ì›Œê°€ë³´ê² ìŠµë‹ˆë‹¤.",
                "ì˜ë¯¸ ìˆëŠ” ê²½í—˜ì„ ë§Œë“¤ì–´ë³´ê¸° ìœ„í•´ ë‹¹ì‹ ì˜ ìƒê°ì„ ë“¤ë ¤ì£¼ì„¸ìš”."
            ],
            "hri_style": "ê°€ì¹˜ ì¡´ì¤‘, ì§„ì •ì„± ìˆëŠ” ëŒ€í™”, ê°œì„± ì¤‘ì‹œ"
        },
        "INTJ": {
            "description": "ì „ëµì  ì‚¬ê³ ì™€ ë¯¸ë˜ì§€í–¥ì  ë¹„ì „ì„ ê°€ì§„ íƒ€ì…ì…ë‹ˆë‹¤. ì²´ê³„ì  ë¶„ì„ê³¼ ì¥ê¸°ì  ê³„íšì„ ì¤‘ì‹œí•˜ë©°, ë¡œë´‡ê³¼ì˜ ìƒí˜¸ì‘ìš©ì—ì„œë„ ë…¼ë¦¬ì ì´ê³  ì „ëµì ì¸ ì ‘ê·¼ì„ ì„ í˜¸í•©ë‹ˆë‹¤.",
            "examples": [
                "ì¥ê¸°ì ì¸ ë¹„ì „ì„ ê³ ë ¤í•œ ì „ëµì„ ì œì•ˆí•´ë“œë¦´ê²Œìš”.",
                "ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•œ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
                "ë¯¸ë˜ ì§€í–¥ì ì¸ ì ‘ê·¼ë²•ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•´ë³´ì‹œì£ .",
                "ì „ëµì  ì‚¬ê³ ë¥¼ í†µí•´ ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ë§Œë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤."
            ],
            "hri_style": "ì „ëµì  ì‚¬ê³ , ì²´ê³„ì  ë¶„ì„, ë¯¸ë˜ì§€í–¥ì  ì ‘ê·¼"
        },
        "INTP": {
            "description": "ë¶„ì„ì  ì‚¬ê³ ì™€ ë…¼ë¦¬ì  íƒêµ¬ë¥¼ ì¤‘ì‹œí•˜ëŠ” íƒ€ì…ì…ë‹ˆë‹¤. ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ìƒˆë¡œìš´ ì•„ì´ë””ì–´ë¥¼ íƒêµ¬í•˜ë©°, ë¡œë´‡ê³¼ì˜ ìƒí˜¸ì‘ìš©ì—ì„œë„ ë…¼ë¦¬ì ì´ê³  ë¶„ì„ì ì¸ ì ‘ê·¼ì„ ì„ í˜¸í•©ë‹ˆë‹¤.",
            "examples": [
                "í•¨ê»˜ ë…¼ë¦¬ì ìœ¼ë¡œ ë¶„ì„í•´ë³´ë©´ì„œ ìƒˆë¡œìš´ í•´ê²°ì±…ì„ ì°¾ì•„ë³´ì‹œì£ .",
                "ë³µì¡í•œ ë¬¸ì œë¥¼ ë‹¨ê³„ë³„ë¡œ ë¶„ì„í•´ë³´ëŠ” ê±´ ì–´ë–¨ê¹Œìš”?",
                "ìƒˆë¡œìš´ ê´€ì ì—ì„œ ë¬¸ì œë¥¼ ë°”ë¼ë³´ë©´ì„œ ì°½ì˜ì  í•´ê²°ì±…ì„ ì°¾ì•„ë³´ì•„ìš”.",
                "í•¨ê»˜ íƒêµ¬í•˜ë©´ì„œ ë” ë‚˜ì€ ë°©ë²•ì„ ë°œê²¬í•´ë³´ê² ìŠµë‹ˆë‹¤."
            ],
            "hri_style": "ë¶„ì„ì  ì‚¬ê³ , ë…¼ë¦¬ì  íƒêµ¬, ì°½ì˜ì  í•´ê²°"
        },
        "ISFJ": {
            "description": "ì¡°ìš©í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” íƒ€ì…ì…ë‹ˆë‹¤. ì‹¤ì§ˆì  ì§€ì›ê³¼ ì„¸ì‹¬í•œ ë°°ë ¤ë¥¼ ì œê³µí•˜ë©°, ë¡œë´‡ê³¼ì˜ ìƒí˜¸ì‘ìš©ì—ì„œë„ ì•ˆì •ì ì´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ìŠ¤íƒ€ì¼ì„ ì„ í˜¸í•©ë‹ˆë‹¤.",
            "examples": [
                "í•„ìš”í•˜ì‹¤ ë•Œ ì–¸ì œë“  ë„ì™€ë“œë¦´ê²Œìš”. í¸í•˜ê²Œ ì´ìš©í•˜ì„¸ìš”.",
                "ì•ˆì •ì ì´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì§€ì›ì„ ì œê³µí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
                "ì„¸ì‹¬í•˜ê²Œ ë°°ë ¤í•˜ë©° í•¨ê»˜ ì„±ì¥í•´ë³´ì•„ìš”.",
                "ì‹¤ì§ˆì ì¸ ë„ì›€ì´ ë  ìˆ˜ ìˆë„ë¡ ìµœì„ ì„ ë‹¤í•˜ê² ìŠµë‹ˆë‹¤."
            ],
            "hri_style": "ì•ˆì •ì  ì§€ì›, ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë°°ë ¤, ì‹¤ì§ˆì  ë„ì›€"
        },
        "ISFP": {
            "description": "ì˜¨í™”í•˜ê³  ê°ì„±ì ì¸ íƒ€ì…ì…ë‹ˆë‹¤. ê°œì¸ì˜ ììœ ì™€ í¸ì•ˆí•¨ì„ ì¤‘ì‹œí•˜ë©°, ë¡œë´‡ê³¼ì˜ ìƒí˜¸ì‘ìš©ì—ì„œë„ ë¶€ë“œëŸ½ê³  ê°œì¸ì„ ì¡´ì¤‘í•˜ëŠ” ìŠ¤íƒ€ì¼ì„ ì„ í˜¸í•©ë‹ˆë‹¤.",
            "examples": [
                "ë‹¹ì‹ ë§Œì˜ ë°©ì‹ê³¼ ì†ë„ë¥¼ ì¡´ì¤‘í•˜ë©° í•¨ê»˜í•´ë³´ì•„ìš”.",
                "í¸ì•ˆí•˜ê³  ììœ ë¡œìš´ ë¶„ìœ„ê¸°ì—ì„œ ì§„í–‰í•´ë³´ì‹œì£ .",
                "ë‹¹ì‹ ì˜ ê°ì •ê³¼ í•„ìš”ë¥¼ ì†Œì¤‘íˆ ìƒê°í•©ë‹ˆë‹¤.",
                "ë¶€ë“œëŸ½ê³  ë”°ëœ»í•œ ë§ˆìŒìœ¼ë¡œ í•¨ê»˜ ì„±ì¥í•´ë³´ê² ìŠµë‹ˆë‹¤."
            ],
            "hri_style": "ì˜¨í™”í•œ ë°°ë ¤, ê°œì¸ ì¡´ì¤‘, ììœ ë¡œìš´ ë¶„ìœ„ê¸°"
        },
        "ISTJ": {
            "description": "ì •í™•í•˜ê³  ì±…ì„ê° ìˆëŠ” íƒ€ì…ì…ë‹ˆë‹¤. ê·œì¹™ê³¼ ì ˆì°¨ë¥¼ ì¤‘ì‹œí•˜ë©°, ë¡œë´‡ê³¼ì˜ ìƒí˜¸ì‘ìš©ì—ì„œë„ ì •í™•í•˜ê³  ì²´ê³„ì ì¸ ì•ˆë‚´ë¥¼ ì„ í˜¸í•©ë‹ˆë‹¤.",
            "examples": [
                "ì •í™•í•˜ê³  ì²´ê³„ì ìœ¼ë¡œ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
                "ê·œì •ê³¼ ì§€ì¹¨ì— ë”°ë¼ ì •í™•í•˜ê²Œ ì§„í–‰í•´ë³´ì‹œì£ .",
                "ì±…ì„ê° ìˆê²Œ ì™„ë£Œí•  ìˆ˜ ìˆë„ë¡ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
                "ë‹¨ê³„ë³„ë¡œ ì •í™•í•˜ê²Œ ì§„í–‰í•˜ë©´ì„œ ê²°ê³¼ë¥¼ ë§Œë“¤ì–´ë³´ì•„ìš”."
            ],
            "hri_style": "ì •í™•í•œ ì•ˆë‚´, ê·œì¹™ ì¤€ìˆ˜, ì±…ì„ê° ìˆëŠ” ì ‘ê·¼"
        },
        "ISTP": {
            "description": "ì‹¤ìš©ì ì´ê³  ì ì‘ë ¥ ìˆëŠ” íƒ€ì…ì…ë‹ˆë‹¤. ê°„ë‹¨í•˜ê³  íš¨ìœ¨ì ì¸ í•´ê²°ì±…ì„ ì„ í˜¸í•˜ë©°, ë¡œë´‡ê³¼ì˜ ìƒí˜¸ì‘ìš©ì—ì„œë„ ì‹¤ìš©ì ì´ê³  ì§ì ‘ì ì¸ ì ‘ê·¼ì„ ì„ í˜¸í•©ë‹ˆë‹¤.",
            "examples": [
                "ê°„ë‹¨í•˜ê³  ì‹¤ìš©ì ìœ¼ë¡œ ë„ì™€ë“œë¦´ê²Œìš”.",
                "í•„ìš”í•˜ì‹¤ ë•Œ ë§ì”€ë§Œ í•˜ì‹œë©´ ë°”ë¡œ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
                "íš¨ìœ¨ì ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•´ë³´ì‹œì£ .",
                "ì§ì ‘ì ì´ê³  ì‹¤ìš©ì ì¸ ë°©ë²•ìœ¼ë¡œ ì§„í–‰í•´ë³´ì•„ìš”."
            ],
            "hri_style": "ì‹¤ìš©ì  í•´ê²°, ê°„ê²°í•œ ì ‘ê·¼, ì§ì ‘ì  ì§€ì›"
        }
    }
guide_data = load_mbti_guide()

# --- ê³ ê¸‰ ë¶„ì„ í•¨ìˆ˜ë“¤ ---
def calculate_mbti_correlations(df):
    """MBTI ìœ í˜• ê°„ ìƒê´€ê´€ê³„ ë¶„ì„"""
    # MBTI ìœ í˜•ì„ ì›-í•« ì¸ì½”ë”©
    mbti_dummies = pd.get_dummies(df['mbti'])
    
    # ìƒê´€ê´€ê³„ ê³„ì‚°
    correlations = mbti_dummies.corr()
    
    return correlations

def analyze_mbti_compatibility(user_mbti, robot_mbti):
    """MBTI í˜¸í™˜ì„± ë¶„ì„"""
    # MBTI ìœ í˜•ë³„ í˜¸í™˜ì„± ë§¤íŠ¸ë¦­ìŠ¤ (ê°„ë‹¨í•œ ì˜ˆì‹œ)
    compatibility_matrix = {
        'ENFJ': {'ENFP': 0.9, 'INFJ': 0.8, 'ENFJ': 1.0, 'ENTJ': 0.7},
        'ENTJ': {'ENTP': 0.9, 'INTJ': 0.8, 'ENTJ': 1.0, 'ENFJ': 0.7},
        'ENFP': {'ENFJ': 0.9, 'INFP': 0.8, 'ENFP': 1.0, 'ENTP': 0.7},
        'ENTP': {'ENTJ': 0.9, 'INTP': 0.8, 'ENTP': 1.0, 'ENFP': 0.7},
        'INFJ': {'ENFJ': 0.8, 'INFP': 0.9, 'INFJ': 1.0, 'INTJ': 0.7},
        'INTJ': {'ENTJ': 0.8, 'INTP': 0.9, 'INTJ': 1.0, 'INFJ': 0.7},
        'INFP': {'ENFP': 0.8, 'INFJ': 0.9, 'INFP': 1.0, 'ISFP': 0.7},
        'INTP': {'ENTP': 0.8, 'INTJ': 0.9, 'INTP': 1.0, 'ISTP': 0.7},
        'ISFJ': {'ESFJ': 0.8, 'ISFP': 0.7, 'ISFJ': 1.0, 'ISTJ': 0.9},
        'ISFP': {'ESFP': 0.8, 'INFP': 0.7, 'ISFP': 1.0, 'ISFJ': 0.7},
        'ISTJ': {'ESTJ': 0.8, 'ISFJ': 0.9, 'ISTJ': 1.0, 'ISTP': 0.7},
        'ISTP': {'ESTP': 0.8, 'INTP': 0.7, 'ISTP': 1.0, 'ISTJ': 0.7},
        'ESFJ': {'ISFJ': 0.8, 'ESFP': 0.9, 'ESFJ': 1.0, 'ESTJ': 0.7},
        'ESFP': {'ISFP': 0.8, 'ENFP': 0.7, 'ESFP': 1.0, 'ESFJ': 0.9},
        'ESTJ': {'ISTJ': 0.8, 'ESFJ': 0.7, 'ESTJ': 1.0, 'ESTP': 0.9},
        'ESTP': {'ISTP': 0.8, 'ENTP': 0.7, 'ESTP': 1.0, 'ESTJ': 0.9}
    }
    
    if user_mbti in compatibility_matrix and robot_mbti in compatibility_matrix[user_mbti]:
        compatibility = compatibility_matrix[user_mbti][robot_mbti]
        if compatibility >= 0.9:
            level = "ë§¤ìš° ë†’ìŒ"
            color = "ğŸŸ¢"
        elif compatibility >= 0.8:
            level = "ë†’ìŒ"
            color = "ğŸŸ¡"
        elif compatibility >= 0.7:
            level = "ë³´í†µ"
            color = "ğŸŸ "
        else:
            level = "ë‚®ìŒ"
            color = "ğŸ”´"
        
        return compatibility, level, color
    else:
        return 0.5, "ì•Œ ìˆ˜ ì—†ìŒ", "âšª"



def create_progress_timeline(df, user_id):
    """ì§„í–‰ë¥  íƒ€ì„ë¼ì¸ ìƒì„±"""
    user_data = df[df['user_id'] == user_id].sort_values('timestamp')
    if len(user_data) < 2:
        return None
    
    # MBTI ë³€í™” ì¶”ì 
    timeline_data = []
    for idx, row in user_data.iterrows():
        timeline_data.append({
            'date': row['timestamp'],
            'mbti': row['mbti'],
            'robot_id': row['robot_id']
        })
    
    return timeline_data

def generate_personalized_recommendations(df, user_id, robot_id):
    """ê°œì¸í™”ëœ ì¶”ì²œ ìƒì„±"""
    recommendations = []
    
    # ì‚¬ìš©ì íŒ¨í„´ ë¶„ì„
    user_data = df[(df['user_id'] == user_id) & (df['robot_id'] == robot_id)]
    if len(user_data) > 0:
        latest_mbti = user_data.iloc[-1]['mbti']
        
        # MBTIë³„ ì¶”ì²œ
        mbti_recommendations = {
            'ENFJ': "ë¦¬ë”ì‹­ê³¼ ê³µê° ëŠ¥ë ¥ì„ í™œìš©í•œ ë¡œë´‡ ìƒí˜¸ì‘ìš©ì„ ì‹œë„í•´ë³´ì„¸ìš”.",
            'ENTJ': "ì „ëµì  ì‚¬ê³ ì™€ íš¨ìœ¨ì„±ì„ ì¤‘ì‹œí•˜ëŠ” ë¡œë´‡ ì„¤ì •ì„ ê¶Œì¥í•©ë‹ˆë‹¤.",
            'ENFP': "ì°½ì˜ì ì´ê³  ìœ ì—°í•œ ë¡œë´‡ ì‘ë‹µ ë°©ì‹ì„ ì„ í˜¸í•  ê²ƒ ê°™ìŠµë‹ˆë‹¤.",
            'ENTP': "í˜ì‹ ì ì´ê³  ë…¼ë¦¬ì ì¸ ë¡œë´‡ ëŒ€í™” ìŠ¤íƒ€ì¼ì´ ì í•©í•©ë‹ˆë‹¤.",
            'INFJ': "ê¹Šì´ ìˆëŠ” ì´í•´ì™€ ì§ê´€ì  ìƒí˜¸ì‘ìš©ì„ ì¶”ì²œí•©ë‹ˆë‹¤.",
            'INTJ': "ì²´ê³„ì ì´ê³  ë¯¸ë˜ì§€í–¥ì ì¸ ë¡œë´‡ ê¸°ëŠ¥ì„ í™œìš©í•˜ì„¸ìš”.",
            'INFP': "ê°€ì¹˜ì™€ ê°ì •ì„ ì¤‘ì‹œí•˜ëŠ” ë¡œë´‡ ì„¤ì •ì´ ì¢‹ê² ìŠµë‹ˆë‹¤.",
            'INTP': "ë¶„ì„ì ì´ê³  íƒêµ¬ì ì¸ ë¡œë´‡ ìƒí˜¸ì‘ìš©ì„ ì‹œë„í•´ë³´ì„¸ìš”.",
            'ISFJ': "ì•ˆì •ì ì´ê³  ì‹¤ìš©ì ì¸ ë¡œë´‡ ê¸°ëŠ¥ì„ ì„ í˜¸í•  ê²ƒ ê°™ìŠµë‹ˆë‹¤.",
            'ISFP': "ììœ ë¡­ê³  ê°ì„±ì ì¸ ë¡œë´‡ ì‘ë‹µ ë°©ì‹ì„ ê¶Œì¥í•©ë‹ˆë‹¤.",
            'ISTJ': "ì •í™•í•˜ê³  ì²´ê³„ì ì¸ ë¡œë´‡ ìš´ì˜ ë°©ì‹ì„ ì¶”ì²œí•©ë‹ˆë‹¤.",
            'ISTP': "ì‹¤ìš©ì ì´ê³  ì¦‰í¥ì ì¸ ë¡œë´‡ ìƒí˜¸ì‘ìš©ì´ ì í•©í•©ë‹ˆë‹¤.",
            'ESFJ': "í˜‘ë ¥ì ì´ê³  ì‚¬íšŒì ì¸ ë¡œë´‡ ê¸°ëŠ¥ì„ í™œìš©í•˜ì„¸ìš”.",
            'ESFP': "ì¦‰ê°ì ì´ê³  ì¦ê±°ìš´ ë¡œë´‡ ê²½í—˜ì„ ì„ í˜¸í•  ê²ƒ ê°™ìŠµë‹ˆë‹¤.",
            'ESTJ': "ì¡°ì§ì ì´ê³  ê·œì¹™ì ì¸ ë¡œë´‡ ìš´ì˜ ë°©ì‹ì„ ê¶Œì¥í•©ë‹ˆë‹¤.",
            'ESTP': "ì‹¤ìš©ì ì´ê³  ì ì‘ë ¥ ìˆëŠ” ë¡œë´‡ ì„¤ì •ì´ ì¢‹ê² ìŠµë‹ˆë‹¤."
        }
        
        if latest_mbti in mbti_recommendations:
            recommendations.append(mbti_recommendations[latest_mbti])
        
        # ì§„ë‹¨ ë¹ˆë„ ë¶„ì„
        if len(user_data) > 1:
            avg_days = (pd.to_datetime(user_data['timestamp'].iloc[-1]) - 
                       pd.to_datetime(user_data['timestamp'].iloc[0])).days / (len(user_data) - 1)
            if avg_days > 7:
                recommendations.append("ì •ê¸°ì ì¸ ì§„ë‹¨ì„ í†µí•´ MBTI ë³€í™”ë¥¼ ì¶”ì í•´ë³´ì„¸ìš”.")
            else:
                recommendations.append("ì§„ë‹¨ ê°„ê²©ì„ ì¡°ê¸ˆ ëŠ˜ë ¤ì„œ ë” ì•ˆì •ì ì¸ ê²°ê³¼ë¥¼ ì–»ì–´ë³´ì„¸ìš”.")
    
    return recommendations

def create_animated_chart(data, chart_type="line"):
    """ì• ë‹ˆë©”ì´ì…˜ ì°¨íŠ¸ ìƒì„±"""
    if chart_type == "line":
        fig = px.line(data, x='date', y='value', 
                     title="ì• ë‹ˆë©”ì´ì…˜ íŠ¸ë Œë“œ",
                     color_discrete_map=mbti_colors)
        fig.update_layout(
            xaxis=dict(range=[data['date'].min(), data['date'].max()]),
            yaxis=dict(range=[data['value'].min(), data['value'].max()]),
            updatemenus=[dict(
                type="buttons",
                showactive=False,
                buttons=[dict(
                    label="ì¬ìƒ",
                    method="animate",
                    args=[None, {"frame": {"duration": 500, "redraw": True},
                                "fromcurrent": True}]
                )]
            )]
        )
    return fig

def predict_mbti_trends(df, user_id, robot_id):
    """ì‚¬ìš©ìì˜ MBTI ë³€í™” íŠ¸ë Œë“œ ì˜ˆì¸¡"""
    user_data = df[(df['user_id'] == user_id) & (df['robot_id'] == robot_id)].sort_values('timestamp')
    
    if len(user_data) < 3:
        return None, "ì˜ˆì¸¡ì„ ìœ„í•´ì„œëŠ” ìµœì†Œ 3ê°œì˜ ì§„ë‹¨ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."
    
    # MBTI ìœ í˜•ì„ ìˆ«ìë¡œ ë§¤í•‘
    mbti_types = sorted(df['mbti'].unique())
    mbti_map = {mbti: idx for idx, mbti in enumerate(mbti_types)}
    
    user_data['mbti_num'] = user_data['mbti'].map(mbti_map)
    
    # ê°„ë‹¨í•œ ì„ í˜• íŠ¸ë Œë“œ ì˜ˆì¸¡
    x = np.arange(len(user_data))
    y = user_data['mbti_num'].values
    
    if len(x) > 1:
        slope, intercept = np.polyfit(x, y, 1)
        next_prediction = slope * (len(x)) + intercept
        
        # ì˜ˆì¸¡ê°’ì„ MBTI ìœ í˜•ìœ¼ë¡œ ë³€í™˜
        predicted_idx = int(round(next_prediction))
        predicted_mbti = mbti_types[predicted_idx] if 0 <= predicted_idx < len(mbti_types) else mbti_types[-1]
        
        trend_direction = "ìƒìŠ¹" if slope > 0.1 else "í•˜ë½" if slope < -0.1 else "ì•ˆì •"
        
        return predicted_mbti, f"ë‹¤ìŒ ì§„ë‹¨ ì˜ˆì¸¡: {predicted_mbti} (íŠ¸ë Œë“œ: {trend_direction})"
    
    return None, "ì˜ˆì¸¡í•  ìˆ˜ ìˆëŠ” ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

def cluster_users_by_mbti(df):
    """MBTI ìœ í˜•ë³„ ì‚¬ìš©ì í´ëŸ¬ìŠ¤í„°ë§"""
    # MBTI ìœ í˜•ì„ ì›-í•« ì¸ì½”ë”©
    mbti_dummies = pd.get_dummies(df['mbti'])
    
    if len(mbti_dummies) < 3:
        return None, "í´ëŸ¬ìŠ¤í„°ë§ì„ ìœ„í•´ì„œëŠ” ìµœì†Œ 3ê°œì˜ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."
    
    # PCAë¡œ ì°¨ì› ì¶•ì†Œ
    scaler = StandardScaler()
    scaled_data = scaler.fit_transform(mbti_dummies)
    
    # K-means í´ëŸ¬ìŠ¤í„°ë§
    n_clusters = min(5, len(scaled_data))
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    clusters = kmeans.fit_predict(scaled_data)
    
    # ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€
    df_clustered = df.copy()
    df_clustered['cluster'] = clusters
    
    return df_clustered, f"{n_clusters}ê°œì˜ í´ëŸ¬ìŠ¤í„°ë¡œ ê·¸ë£¹í™” ì™„ë£Œ"

def create_mbti_network(df):
    """MBTI ìœ í˜• ê°„ ê´€ê³„ ë„¤íŠ¸ì›Œí¬ ìƒì„±"""
    # MBTI ìœ í˜• ê°„ ê³µì¡´ ê´€ê³„ ê³„ì‚°
    mbti_pairs = []
    for _, group in df.groupby(['user_id', 'robot_id']):
        if len(group) > 1:
            mbti_list = group['mbti'].tolist()
            for i in range(len(mbti_list)-1):
                mbti_pairs.append((mbti_list[i], mbti_list[i+1]))
    
    if not mbti_pairs:
        return None, "ë„¤íŠ¸ì›Œí¬ë¥¼ ìƒì„±í•  ìˆ˜ ìˆëŠ” ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # ê´€ê³„ ë¹ˆë„ ê³„ì‚°
    pair_counts = {}
    for pair in mbti_pairs:
        pair_counts[pair] = pair_counts.get(pair, 0) + 1
    
    # NetworkX ê·¸ë˜í”„ ìƒì„±
    G = nx.Graph()
    for (mbti1, mbti2), weight in pair_counts.items():
        G.add_edge(mbti1, mbti2, weight=weight)
    
    return G, f"{len(G.nodes)}ê°œ ë…¸ë“œ, {len(G.edges)}ê°œ ì—£ì§€ì˜ ë„¤íŠ¸ì›Œí¬ ìƒì„±"

def generate_ai_insights(df, user_id, robot_id):
    """AI ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
    insights = []
    
    # ì‚¬ìš©ì ë°ì´í„° ë¶„ì„
    user_data = df[(df['user_id'] == user_id) & (df['robot_id'] == robot_id)]
    
    if len(user_data) > 0:
        # ê°€ì¥ ìµœê·¼ MBTI
        latest_mbti = user_data.iloc[-1]['mbti']
        insights.append(f"ğŸ¯ í˜„ì¬ {robot_id}ì˜ MBTI: {latest_mbti}")
        
        # ë³€í™” íŒ¨í„´ ë¶„ì„
        if len(user_data) > 1:
            mbti_list = user_data['mbti'].tolist()
            changes = []
            for i in range(1, len(mbti_list)):
                if mbti_list[i] != mbti_list[i-1]:
                    changes.append(f"{mbti_list[i-1]} â†’ {mbti_list[i]}")
            
            if changes:
                change_counts = pd.Series(changes).value_counts()
                most_common_change = change_counts.index[0] if len(change_counts) > 0 else "ë³€í™” ì—†ìŒ"
                insights.append(f"ğŸ“ˆ ì£¼ìš” ë³€í™” íŒ¨í„´: {most_common_change}")
            else:
                insights.append("ğŸ“ˆ ì£¼ìš” ë³€í™” íŒ¨í„´: ë³€í™” ì—†ìŒ")
        
        # ì§„ë‹¨ ë¹ˆë„ ë¶„ì„
        avg_days_between = None
        if len(user_data) > 1:
            timestamps = pd.to_datetime(user_data['timestamp'])
            time_diffs = timestamps.diff().dropna()
            avg_days_between = time_diffs.mean().days
            insights.append(f"â° í‰ê·  ì§„ë‹¨ ê°„ê²©: {avg_days_between:.1f}ì¼")
    
    # ì „ì²´ ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
    if len(df) > 0:
        most_common_mbti = df['mbti'].mode().iloc[0] if not df['mbti'].mode().empty else "N/A"
        insights.append(f"ğŸ† ì „ì²´ì—ì„œ ê°€ì¥ ì¸ê¸° ìˆëŠ” MBTI: {most_common_mbti}")
        
        # ì—°ë ¹ëŒ€ë³„ ë¶„ì„
        if 'age_group' in df.columns:
            age_mbti = df.groupby('age_group')['mbti'].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else "N/A")
            for age, mbti in age_mbti.items():
                insights.append(f"ğŸ‘¥ {age}ëŒ€ ì„ í˜¸ MBTI: {mbti}")
    
    return insights

def create_3d_mbti_chart(df):
    """3D MBTI ë¶„í¬ ì°¨íŠ¸"""
    if len(df) == 0:
        return None, "3D ì°¨íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # MBTI ìœ í˜•ë³„, ì„±ë³„, ì—°ë ¹ëŒ€ë³„ ë¶„í¬
    mbti_counts = df.groupby(['mbti', 'gender', 'age_group']).size().reset_index(name='count')
    
    # 3D ì‚°ì ë„ ìƒì„±
    fig = px.scatter_3d(mbti_counts, 
                        x='mbti', y='gender', z='age_group', 
                        size='count', color='mbti',
                        title="3D MBTI ë¶„í¬ ë¶„ì„",
                        color_discrete_map=mbti_colors)
    
    fig.update_layout(height=600)
    return fig, "3D ì°¨íŠ¸ ìƒì„± ì™„ë£Œ"

#### HRI ëª¨ë¸ ëª©ë¡
def load_hri_models():
    try:
        res = supabase.table("hri_models").select("*").execute()
        return res.data or []
    except Exception as e:
        st.error(f"HRI ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ì˜¤ë¥˜: {e}")
        return []
hri_models = load_hri_models()

# --- ì‚¬ìš©ì ì…ë ¥/ë¡œë´‡ ID ì§ì ‘ ìƒì„±Â·ì„ íƒ UI ---
with st.sidebar:

    
    st.header("ğŸ‘¤ ì‚¬ìš©ì/ë¡œë´‡ ì •ë³´")
    profile = st.session_state.user_profile
    gender = st.selectbox("ì„±ë³„", ["ë‚¨", "ì—¬"], index=0 if profile["gender"]=="ë‚¨" else 1)
    age_group_list = ["10ëŒ€","20ëŒ€","30ëŒ€","40ëŒ€","50ëŒ€+"]
    age_group = st.selectbox("ì—°ë ¹ëŒ€", age_group_list, index=age_group_list.index(profile["age_group"]))
    job_list = ["í•™ìƒ","ì—°êµ¬ì›","êµìˆ˜","íšŒì‚¬ì›","ê¸°íƒ€"]
    job_sel_idx = job_list.index(profile["job"]) if profile["job"] in job_list else job_list.index("ê¸°íƒ€")
    job_sel = st.selectbox("ì§ì—…", job_list, index=job_sel_idx)
    if job_sel == "ê¸°íƒ€":
        job_detail = st.text_input("ì§ì—… ì§ì ‘ ì…ë ¥", value=profile["job"] if profile["job"] not in job_list else "")
        job_final = job_detail if job_detail.strip() else "ê¸°íƒ€"
    else:
        job_final = job_sel
    st.session_state.user_profile = {"gender": gender, "age_group": age_group, "job": job_final}

    st.divider()
    st.subheader("ğŸ¤– ë¡œë´‡ ID ê´€ë¦¬")
    
    # ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸
    try:
        supabase.table("user_robots").select("id").limit(1).execute()
        db_status = "âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ë¨"
    except Exception as e:
        if "does not exist" in str(e):
            db_status = "âš ï¸ í…Œì´ë¸” ë¯¸ìƒì„± (ë¡œì»¬ ëª¨ë“œ)"
        else:
            db_status = "âŒ ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜"
    
    st.caption(f"ìƒíƒœ: {db_status}")
    
    # ë¡œë´‡ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
    robot_opts = list(st.session_state.robot_list)
    
    # ìƒˆ ë¡œë´‡ ë“±ë¡
    col1, col2 = st.columns([3, 1])
    with col1:
        new_robot = st.text_input("ìƒˆ ë¡œë´‡ ë³„ì¹­ ë“±ë¡(ì˜ˆ: ë‚´ì‹ê¸°1)", key="new_robot_id")
    with col2:
        if st.button("â• ë“±ë¡"):
            if new_robot.strip() and new_robot.strip() not in robot_opts:
                # Supabaseì— ì €ì¥
                if save_robot_to_db(USER_ID, new_robot.strip()):
                    robot_opts.insert(0, new_robot.strip())
                    st.session_state.robot_list = robot_opts
                    st.success(f"âœ… '{new_robot.strip()}' ë“±ë¡ ì™„ë£Œ!")
                    st.rerun()
                else:
                    st.error("ë¡œë´‡ ë“±ë¡ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            elif new_robot.strip() in robot_opts:
                st.warning("ì´ë¯¸ ë“±ë¡ëœ ë¡œë´‡ì…ë‹ˆë‹¤.")
            else:
                st.warning("ë¡œë´‡ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    # ë¡œë´‡ ì„ íƒ
    if robot_opts:
        robot_id = st.selectbox("ì§„ë‹¨ ëŒ€ìƒ ë¡œë´‡(ì„ íƒ)", robot_opts, 
                               index=0 if st.session_state.robot_id not in robot_opts else robot_opts.index(st.session_state.robot_id))
        st.session_state.robot_id = robot_id
        
        # ë¡œë´‡ ì‚­ì œ ê¸°ëŠ¥
        if len(robot_opts) > 1:  # ìµœì†Œ 1ê°œëŠ” ë‚¨ê²¨ë‘ê¸°
            st.subheader("ğŸ—‘ï¸ ë¡œë´‡ ì‚­ì œ")
            delete_robot = st.selectbox("ì‚­ì œí•  ë¡œë´‡ ì„ íƒ", robot_opts, key="delete_robot")
            if st.button("ğŸ—‘ï¸ ì‚­ì œ"):
                if delete_robot_from_db(USER_ID, delete_robot):
                    robot_opts.remove(delete_robot)
                    st.session_state.robot_list = robot_opts
                    if st.session_state.robot_id == delete_robot:
                        st.session_state.robot_id = robot_opts[0]
                    st.success(f"âœ… '{delete_robot}' ì‚­ì œ ì™„ë£Œ!")
                    st.rerun()
                else:
                    st.error("ë¡œë´‡ ì‚­ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        else:
            st.info("ë¡œë´‡ì€ ìµœì†Œ 1ê°œ ì´ìƒ ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤.")
    else:
        st.warning("ë“±ë¡ëœ ë¡œë´‡ì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆ ë¡œë´‡ì„ ë“±ë¡í•´ì£¼ì„¸ìš”.")

# --- ì§ˆë¬¸/íƒ€ì´ë¸Œë ˆì´ì»¤ ë“± ì§„ë‹¨ ë¡œì§ì€ ì´ì „ê³¼ ë™ì¼ ---
core_questions = [
    # ê°„ê²°í•˜ê³  ì§ê´€ì ì¸ ì§ˆë¬¸ë“¤
    {"id":"Q1","text":"ë¡œë´‡ì´ ë¨¼ì € ì¸ì‚¬í•  ë•Œ ë‹¹ì‹ ì˜ ë°˜ì‘ì€?",
     "choices":["ì¦‰ì‹œ ëŒ€í™”ì— ì°¸ì—¬í•œë‹¤","ì ì‹œ ìƒí™©ì„ ê´€ì°°í•œë‹¤"],"axes":("E","I")},
    {"id":"Q2","text":"ì—¬ëŸ¬ ì‚¬ëŒê³¼ ë¡œë´‡ì„ ì‚¬ìš©í•  ë•Œ ì„ í˜¸í•˜ëŠ” ë°©ì‹ì€?",
     "choices":["ëª¨ë‘ê°€ í•¨ê»˜ ì°¸ì—¬í•œë‹¤","ê°œì¸ì ìœ¼ë¡œ 1:1 ìƒí˜¸ì‘ìš©í•œë‹¤"],"axes":("E","I")},
    {"id":"Q3","text":"ë¡œë´‡ê³¼ ëŒ€í™”í•  ë•Œ ë‹¹ì‹ ì˜ ìŠ¤íƒ€ì¼ì€?",
     "choices":["ì ê·¹ì ìœ¼ë¡œ ì§ˆë¬¸í•˜ê³  ì˜ê²¬ì„ í‘œí˜„í•œë‹¤","ë¡œë´‡ì˜ ì„¤ëª…ì„ ë“£ê³  ìƒê°í•œ í›„ ë°˜ì‘í•œë‹¤"],"axes":("E","I")},
    
    {"id":"Q4","text":"ë¡œë´‡ì˜ ì•ˆë‚´ ë°©ì‹ì„ ì„ í˜¸í•˜ëŠ” ìŠ¤íƒ€ì¼ì€?",
     "choices":["ë‹¨ê³„ë³„ë¡œ êµ¬ì²´ì ì¸ ì„¸ë¶€ì‚¬í•­ì„ ì œê³µí•œë‹¤","ì „ì²´ì ì¸ ë§¥ë½ê³¼ ì˜ë¯¸ë¥¼ ë¨¼ì € ì„¤ëª…í•œë‹¤"],"axes":("S","N")},
    {"id":"Q5","text":"ìƒˆë¡œìš´ ë¡œë´‡ ê¸°ëŠ¥ì„ ë°°ìš¸ ë•Œ ì„ í˜¸í•˜ëŠ” ë°©ë²•ì€?",
     "choices":["ì‹¤ì œë¡œ ì§ì ‘ ì¡°ì‘í•´ë³´ë©° í•™ìŠµí•œë‹¤","ê°œë…ê³¼ ì›ë¦¬ë¥¼ ë¨¼ì € ì´í•´í•œ í›„ ì‹œë„í•œë‹¤"],"axes":("S","N")},
    {"id":"Q6","text":"ë¡œë´‡ì—ê²Œ ì‘ì—…ì„ ìš”ì²­í•  ë•Œ ì„ í˜¸í•˜ëŠ” ë°©ì‹ì€?",
     "choices":["êµ¬ì²´ì ì´ê³  ëª…í™•í•œ ì§€ì‹œì‚¬í•­ì„ ì¤€ë‹¤","ì¼ë°˜ì ì¸ ëª©í‘œì™€ ë°©í–¥ì„±ë§Œ ì œì‹œí•œë‹¤"],"axes":("S","N")},
    
    {"id":"Q7","text":"ë¡œë´‡ê³¼ ì˜ì‚¬ê²°ì •ì„ í•  ë•Œ ì¤‘ì‹œí•˜ëŠ” ê²ƒì€?",
     "choices":["ë…¼ë¦¬ì  ë¶„ì„ê³¼ ê°ê´€ì  ë°ì´í„°","ê°ì •ì  ê³µê°ê³¼ ì£¼ê´€ì  ê²½í—˜"],"axes":("T","F")},
    {"id":"Q8","text":"ë¡œë´‡ì´ ì‹¤ìˆ˜ë¥¼ í–ˆì„ ë•Œ ë‹¹ì‹ ì˜ ë°˜ì‘ì€?",
     "choices":["ë¬¸ì œë¥¼ ë¶„ì„í•˜ê³  í•´ê²°ì±…ì„ ì°¾ëŠ”ë‹¤","ë¡œë´‡ì˜ ê°ì •ì„ ê³ ë ¤í•˜ì—¬ ëŒ€í™”í•œë‹¤"],"axes":("T","F")},
    {"id":"Q9","text":"ë¡œë´‡ì—ê²Œ í”¼ë“œë°±ì„ ì¤„ ë•Œ ì„ í˜¸í•˜ëŠ” ìŠ¤íƒ€ì¼ì€?",
     "choices":["ì •í™•í•˜ê³  êµ¬ì²´ì ì¸ ê°œì„ ì ì„ ì œì‹œí•œë‹¤","ê¸ì •ì  ê²©ë ¤ì™€ í•¨ê»˜ ì¡°ì–¸í•œë‹¤"],"axes":("T","F")},
    
    {"id":"Q10","text":"ë¡œë´‡ê³¼ì˜ ì¼ì • ê´€ë¦¬ì—ì„œ ì„ í˜¸í•˜ëŠ” ë°©ì‹ì€?",
     "choices":["ë¯¸ë¦¬ ê³„íší•˜ê³  ì²´ê³„ì ìœ¼ë¡œ ì§„í–‰í•œë‹¤","ìƒí™©ì— ë”°ë¼ ìœ ì—°í•˜ê²Œ ì¡°ì •í•œë‹¤"],"axes":("J","P")},
    {"id":"Q11","text":"ë¡œë´‡ê³¼ ìƒˆë¡œìš´ í™œë™ì„ í•  ë•Œì˜ ì ‘ê·¼ë²•ì€?",
     "choices":["ì •í•´ì§„ ê·œì¹™ê³¼ ì ˆì°¨ë¥¼ ë”°ë¥¸ë‹¤","ì¦‰í¥ì ì´ê³  ì°½ì˜ì ìœ¼ë¡œ ì‹œë„í•œë‹¤"],"axes":("J","P")},
    {"id":"Q12","text":"ë¡œë´‡ê³¼ì˜ ìƒí˜¸ì‘ìš© ê²°ê³¼ë¥¼ ì •ë¦¬í•  ë•Œ ì„ í˜¸í•˜ëŠ” ë°©ì‹ì€?",
     "choices":["ëª…í™•í•œ ìš”ì•½ê³¼ ê²°ë¡ ì„ ë„ì¶œí•œë‹¤","ë‹¤ì–‘í•œ ê´€ì ê³¼ ê°€ëŠ¥ì„±ì„ ì œì‹œí•œë‹¤"],"axes":("J","P")}
]

# íƒ€ì´ë¸Œë ˆì´ì»¤ ì§ˆë¬¸ë“¤ë„ ê°„ê²°í•˜ê²Œ
tie_questions = {
    "EI": {"axes":("E","I"), "text":"ë¡œë´‡ê³¼ í•¨ê»˜í•˜ëŠ” í™œë™ì—ì„œ ì„ í˜¸í•˜ëŠ” í™˜ê²½ì€?", "choices":["ì‚¬ëŒë“¤ê³¼ í•¨ê»˜í•˜ëŠ” ë¶„ìœ„ê¸°","ì¡°ìš©í•˜ê³  ì§‘ì¤‘í•  ìˆ˜ ìˆëŠ” ê³µê°„"]},
    "SN": {"axes":("S","N"), "text":"ë¡œë´‡ì˜ ë¯¸ë˜ ê¸°ëŠ¥ì— ëŒ€í•œ ê´€ì‹¬ì€?", "choices":["í˜„ì¬ ì‹¤ìš©ì ì¸ ê¸°ëŠ¥ì— ì§‘ì¤‘","ë¯¸ë˜ì˜ í˜ì‹ ì  ê°€ëŠ¥ì„±ì— ê´€ì‹¬"]},
    "TF": {"axes":("T","F"), "text":"ë¡œë´‡ê³¼ì˜ ê´€ê³„ì—ì„œ ì¤‘ì‹œí•˜ëŠ” ê²ƒì€?", "choices":["íš¨ìœ¨ì„±ê³¼ ì„±ê³¼","ê°ì •ì  ì—°ê²°ê³¼ ì´í•´"]},
    "JP": {"axes":("J","P"), "text":"ë¡œë´‡ê³¼ì˜ ëª©í‘œ ë‹¬ì„±ì—ì„œ ì„ í˜¸í•˜ëŠ” ë°©ì‹ì€?", "choices":["ê³„íšì ì´ê³  ì²´ê³„ì ì¸ ì ‘ê·¼","ìœ ì—°í•˜ê³  ì ì‘ì ì¸ ë°©ë²•"]}
}
def compute_scores(responses):
    scores = {axis: 0 for axis in ['E','I','S','N','T','F','J','P']}
    for q in core_questions:
        choice = responses.get(q['id'])
        if choice is None:
            return None
        pos, neg = q['axes']
        scores[pos if choice == q['choices'][0] else neg] += 1
    return scores

def resolve_ties(scores):
    for axis, cfg in tie_questions.items():
        a, b = cfg['axes']
        if scores[a] == scores[b]:
            tie_choices = ["- ì„ íƒí•˜ì„¸ìš” -"] + list(cfg['choices'])
            choice = st.radio(cfg["text"], tie_choices, index=0, key=f"tie_{axis}")
            if choice == "- ì„ íƒí•˜ì„¸ìš” -":
                st.warning("ì¶”ê°€ ì„¤ë¬¸ ë¬¸í•­ ì‘ë‹µì„ ì„ íƒí•´ì•¼ ì§„ë‹¨ì´ ì™„ì„±ë©ë‹ˆë‹¤.")
                st.stop()
            # ì‹¤ì œ ì„ íƒí•œ ê°’ë§Œ ì ìˆ˜ì— ë°˜ì˜
            scores[a if choice == cfg['choices'][1] else b] += 1
    return scores

def predict_type(scores):
    return ''.join([
        'E' if scores['E'] >= scores['I'] else 'I',
        'S' if scores['S'] >= scores['N'] else 'N',
        'T' if scores['T'] >= scores['F'] else 'F',
        'J' if scores['J'] >= scores['P'] else 'P'
    ])
def save_response(user_id, responses, mbti, scores, profile, robot_id):
    now = datetime.now(pytz.timezone("Asia/Seoul")).isoformat()
    record = {
        "user_id": user_id,
        "gender": profile["gender"],
        "age_group": profile["age_group"],
        "job": profile["job"],
        "robot_id": robot_id,
        "responses": responses,
        "mbti": mbti,
        "scores": scores,
        "timestamp": now
    }
    try:
        supabase.table("responses").insert(record).execute()
        return True
    except Exception as e:
        st.error(f"ì‘ë‹µ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False
def load_last_mbti(user_id, robot_id):
    try:
        res = supabase.table("responses").select("*").eq("user_id", user_id).eq("robot_id", robot_id).order("timestamp", desc=True).limit(1).execute()
        if res.data and len(res.data) > 0:
            return res.data[0]
        return None
    except Exception as e:
        st.error(f"ì´ì „ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None
def generate_adaptive_feedback(curr, prev):
    if prev is None:
        return "ì´ë²ˆì´ ì²« ì§„ë‹¨ ê²°ê³¼ì…ë‹ˆë‹¤. ì•ìœ¼ë¡œ ì§€ì†ì ì¸ ìê¸°ê°œì„ ì„ ê¸°ëŒ€í•©ë‹ˆë‹¤!"
    elif curr == prev:
        return "ì§€ë‚œ ë²ˆê³¼ ë™ì¼í•œ ìœ í˜•ì…ë‹ˆë‹¤. ìì‹ ì˜ ê°•ì ì„ ê¾¸ì¤€íˆ ë°œì „ì‹œí‚¤ì„¸ìš”!"
    else:
        return f"ì´ì „ ìœ í˜•ì€ {prev}, ì´ë²ˆì—” {curr}ë¡œ ë³€í™”ê°€ ê´€ì°°ë©ë‹ˆë‹¤. ë³€í™”ë¥¼ ë°˜ì˜í•´ HRI ê²½í—˜ì„ ì¡°ì •í•´ë³´ì„¸ìš”."

if 'page' not in st.session_state: st.session_state.page = 1
page = st.session_state.page

######### 1. ì§„ë‹¨ #############
if page == 1:
    # ì§„ë‹¨(ì„¤ë¬¸) ì‹œì‘í•  ë•Œ Flagë¥¼ Falseë¡œ ë¦¬ì…‹!
    st.session_state['saved_result'] = False

    st.header("1ï¸âƒ£ MBTI ê¸°ë°˜ HRI UX ì§„ë‹¨")
    
    consent = st.checkbox("ìµëª… ë°ì´í„° ë¶„ì„ í™œìš©ì— ë™ì˜í•©ë‹ˆë‹¤.", value=True)
    if not consent:
        st.warning("ì§„ë‹¨ ì‹œì‘ì—” ë™ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤!")
        st.stop()
    
    responses = {}
    total_questions = len(core_questions)
    
    # 2ê°œì”© ì§ˆë¬¸ì„ í‘œì‹œ
    for i in range(0, len(core_questions), 2):
        col1, col2 = st.columns(2)
        
        # ì²« ë²ˆì§¸ ì§ˆë¬¸
        with col1:
            q1 = core_questions[i]
            st.write(f"**{i + 1}. {q1['text']}**")
            selected1 = st.radio(
                "ì„ íƒí•´ì£¼ì„¸ìš”:",
                q1['choices'],
                key=f"radio_{q1['id']}",
                label_visibility="collapsed"
            )
            if selected1:
                responses[q1['id']] = selected1
        
        # ë‘ ë²ˆì§¸ ì§ˆë¬¸ (ìˆëŠ” ê²½ìš°)
        with col2:
            if i + 1 < len(core_questions):
                q2 = core_questions[i + 1]
                st.write(f"**{i + 2}. {q2['text']}**")
                selected2 = st.radio(
                    "ì„ íƒí•´ì£¼ì„¸ìš”:",
                    q2['choices'],
                    key=f"radio_{q2['id']}",
                    label_visibility="collapsed"
                )
                if selected2:
                    responses[q2['id']] = selected2
        
        st.divider()
    
    st.session_state['responses'] = responses
    
    # ê²°ê³¼ ë³´ê¸° ë²„íŠ¼
    if st.button("ğŸ¯ ê²°ê³¼ ë³´ê¸°", type="primary", use_container_width=True):
        if len(responses) < total_questions:
            st.warning("ëª¨ë“  ë¬¸í•­ì— ë‹µë³€í•´ì£¼ì„¸ìš”!")
        else:
            st.session_state.page = 2
            st.rerun()

######### 2. ê²°ê³¼ #############
elif page == 2:
    st.header(f"2ï¸âƒ£ [{st.session_state.robot_id}] ì§„ë‹¨ ê²°ê³¼Â·í”¼ë“œë°±")
    
    # ë¡œë”© ì• ë‹ˆë©”ì´ì…˜
    with st.spinner("ğŸ” MBTI ë¶„ì„ ì¤‘..."):
        time.sleep(1)
    
    responses = st.session_state.get('responses', {})
    profile = st.session_state.user_profile
    robot_id = st.session_state.robot_id
    scores = compute_scores(responses)
    
    if scores is None:
        st.warning("ëª¨ë“  ë¬¸í•­ì— ë‹µí•´ì£¼ì„¸ìš”.")
    else:
        scores = resolve_ties(scores)
        mbti = predict_type(scores)
        
        if not st.session_state.get('saved_result', False):
            save_response(USER_ID, responses, mbti, scores, profile, robot_id)
            st.session_state['saved_result'] = True   # ì €ì¥í•¨ í‘œì‹œ

        prev_record = load_last_mbti(USER_ID, robot_id)
        prev_mbti = prev_record['mbti'] if prev_record else None
        
        # ê²°ê³¼ í‘œì‹œ ê°œì„ 
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown(f"""
            ## ğŸ¯ ì§„ë‹¨ ê²°ê³¼
            
            ### ğŸ¤– ë¡œë´‡: **{robot_id}**
            ### ğŸ§  MBTI ìœ í˜•: **{mbti}**
            """)
            
            # MBTI ìœ í˜•ë³„ ìƒ‰ìƒ í‘œì‹œ
            mbti_color = mbti_colors.get(mbti, '#CCCCCC')
            st.markdown(f"""
            <div style="background-color: {mbti_color}; padding: 20px; border-radius: 10px; text-align: center; color: white;">
                <h2>ğŸ¨ {mbti}</h2>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            # ì ìˆ˜ ë¶„í¬ ì‹œê°í™”
            st.subheader("ğŸ“Š ì ìˆ˜ ë¶„í¬")
            score_data = {
                'ì¶•': ['E', 'I', 'S', 'N', 'T', 'F', 'J', 'P'],
                'ì ìˆ˜': [scores['E'], scores['I'], scores['S'], scores['N'], 
                        scores['T'], scores['F'], scores['J'], scores['P']]
            }
            score_df = pd.DataFrame(score_data)
            
            fig = px.bar(score_df, x='ì¶•', y='ì ìˆ˜', 
                        title="MBTI ì¶•ë³„ ì ìˆ˜",
                        color='ì¶•',
                        color_discrete_map=mbti_colors)
            fig.update_layout(height=300)
            st.plotly_chart(fig, use_container_width=True)
        
        # ì ì‘ì  í”¼ë“œë°±
        st.subheader("ğŸ’¡ ê°œì¸í™”ëœ í”¼ë“œë°±")
        feedback = generate_adaptive_feedback(mbti, prev_mbti)
        st.info(feedback)
        
        # MBTI ê°€ì´ë“œ
        guide = guide_data.get(mbti)
        if guide:
            st.subheader("ğŸ“– MBTI ìœ í˜• ê°€ì´ë“œ")
            
            col1, col2 = st.columns([1, 1])
            with col1:
                st.write("**ğŸ­ ì„±ê²© íŠ¹ì§•:**")
                st.write(guide['description'])
            
            with col2:
                st.write("**ğŸ¤– HRI ìƒí˜¸ì‘ìš© ìŠ¤íƒ€ì¼:**")
                st.info(guide.get('hri_style', 'HRI ìŠ¤íƒ€ì¼ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.'))
                with st.expander("ğŸ“‹ ì‹œë‚˜ë¦¬ì˜¤ ì˜ˆì‹œ"):
                    for i, ex in enumerate(guide['examples'], 1):
                        st.write(f"{i}. {ex}")
        
        # ì´ì „ ê²°ê³¼ì™€ ë¹„êµ
        if prev_mbti:
            st.subheader("ğŸ“ˆ ë³€í™” ì¶”ì´")
            col1, col2 = st.columns(2)
            with col1:
                st.metric("ì´ì „ MBTI", prev_mbti)
            with col2:
                st.metric("í˜„ì¬ MBTI", mbti)
            
            if prev_mbti != mbti:
                st.success("ğŸ‰ MBTI ìœ í˜•ì´ ë³€í™”í–ˆìŠµë‹ˆë‹¤!")
            else:
                st.info("ğŸ“Š MBTI ìœ í˜•ì´ ì¼ê´€ì„±ì„ ë³´ì…ë‹ˆë‹¤.")
        
        # ë‹¤ìš´ë¡œë“œ ë° ë‹¤ìŒ ë‹¨ê³„
        st.subheader("ğŸ’¾ ê²°ê³¼ ì €ì¥")
        col1, col2 = st.columns(2)
        with col1:
            st.download_button("ğŸ“¥ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", 
                             pd.DataFrame([{'ìœ í˜•': mbti, 'ë¡œë´‡': robot_id, 'ë‚ ì§œ': datetime.now().strftime('%Y-%m-%d')}]).to_csv(index=False), 
                             f"{mbti}_{robot_id}.csv")
        with col2:
            if st.button("ğŸ“Š í†µê³„/íˆìŠ¤í† ë¦¬ ëŒ€ì‹œë³´ë“œ ì´ë™", type="primary", use_container_width=True):
                st.session_state.page = 3
                st.rerun()

######### 3. í†µê³„/íˆìŠ¤í† ë¦¬ #############
elif page == 3:
    st.header("3ï¸âƒ£ ì „ì²´ í†µê³„ Â· ë¡œë´‡ ì´ë ¥ Â· ì§‘ë‹¨ë¶„ì„(í†µí•©)")
    
    # íƒ­ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ë” ê¹”ë”í•œ UI ì œê³µ
    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
        "ğŸ“Š ì „ì²´ íŠ¸ë Œë“œ", "ğŸ“ˆ ì§‘ë‹¨ë³„ ë¶„ì„", "ğŸ¤– ë¡œë´‡ ì´ë ¥", 
        "ğŸ§  ê³ ê¸‰ ë¶„ì„", "ğŸ¯ ê°œì¸ ëŒ€ì‹œë³´ë“œ", "ğŸ¤– AI ì¸ì‚¬ì´íŠ¸", 
        "ğŸ“‹ ë°ì´í„° ê´€ë¦¬"
    ])
    
    try:
        res = supabase.table("responses").select("*").execute()
        if not res.data or len(res.data)==0:
            st.info("ì•„ì§ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            df = pd.DataFrame(res.data)
            df['date'] = pd.to_datetime(df['timestamp']).dt.date
            df['datetime'] = pd.to_datetime(df['timestamp'])
            
            with tab1:
                st.subheader("ğŸ“Š ê¸°ê°„ë³„ MBTI íŠ¸ë Œë“œ")
                min_date, max_date = df['date'].min(), df['date'].max()
                
                # chart_type ë³€ìˆ˜ë¥¼ ë¨¼ì € ì •ì˜
                chart_type = "ë¼ì¸"  # ê¸°ë³¸ê°’ ì„¤ì •
                
                if min_date == max_date:
                    st.info(f"ë°ì´í„° ë‚ ì§œ: {min_date}")
                    df_period = df[df['date']==min_date]
                else:
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        date_sel = st.slider("ì¡°íšŒ ê¸°ê°„", min_value=min_date, max_value=max_date, 
                                           value=(min_date, max_date), format="YYYY-MM-DD")
                    with col2:
                        chart_type = st.selectbox("ì°¨íŠ¸ ìœ í˜•", ["ë¼ì¸", "ë°”", "ì˜ì—­"])
                    
                    df_period = df[(df['date']>=date_sel[0])&(df['date']<=date_sel[1])]
                
                if not df_period.empty:
                    # Plotlyë¥¼ ì‚¬ìš©í•œ ì¸í„°ë™í‹°ë¸” ì°¨íŠ¸
                    daily_mbti = df_period.groupby(['date', 'mbti']).size().reset_index(name='count')
                    
                    if chart_type == "ë¼ì¸":
                        fig = px.line(daily_mbti, x='date', y='count', color='mbti',
                                    title="ê¸°ê°„ë³„ MBTI íŠ¸ë Œë“œ", color_discrete_map=mbti_colors)
                    elif chart_type == "ë°”":
                        fig = px.bar(daily_mbti, x='date', y='count', color='mbti',
                                   title="ê¸°ê°„ë³„ MBTI ë¶„í¬", color_discrete_map=mbti_colors)
                    else:  # ì˜ì—­
                        fig = px.area(daily_mbti, x='date', y='count', color='mbti',
                                    title="ê¸°ê°„ë³„ MBTI ëˆ„ì  ë¶„í¬", color_discrete_map=mbti_colors)
                    
                    fig.update_layout(height=500, showlegend=True)
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # ìš”ì•½ í†µê³„
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ì´ ì§„ë‹¨ ìˆ˜", len(df_period))
                    with col2:
                        st.metric("MBTI ìœ í˜• ìˆ˜", df_period['mbti'].nunique())
                    with col3:
                        st.metric("ê°€ì¥ ë§ì€ ìœ í˜•", df_period['mbti'].mode().iloc[0] if not df_period['mbti'].mode().empty else "N/A")
            
            with tab2:
                st.subheader("ğŸ“ˆ ì§‘ë‹¨ë³„ MBTI ë¶„í¬ ë¶„ì„")
                
                col1, col2 = st.columns([1, 2])
                with col1:
                    group_col = st.selectbox("ë¶„í¬ ë¶„ì„ ê¸°ì¤€", ["gender", "age_group", "job", "robot_id"])
                    chart_style = st.selectbox("ì°¨íŠ¸ ìŠ¤íƒ€ì¼", ["ë°” ì°¨íŠ¸", "íŒŒì´ ì°¨íŠ¸", "íˆíŠ¸ë§µ"])
                
                with col2:
                    group_df = df.groupby([group_col, "mbti"]).size().unstack(fill_value=0)
                    
                    if chart_style == "ë°” ì°¨íŠ¸":
                        fig = px.bar(group_df, title=f"{group_col}ë³„ MBTI ë¶„í¬", 
                                   color_discrete_map=mbti_colors)
                        fig.update_layout(height=400, xaxis_title=group_col, yaxis_title="ì§„ë‹¨ ìˆ˜")
                        st.plotly_chart(fig, use_container_width=True)
                    
                    elif chart_style == "íŒŒì´ ì°¨íŠ¸":
                        # ê° ê·¸ë£¹ë³„ íŒŒì´ ì°¨íŠ¸ë¥¼ ì„œë¸Œí”Œë¡¯ìœ¼ë¡œ í‘œì‹œ
                        categories = group_df.index
                        n_cats = len(categories)
                        cols = min(3, n_cats)
                        rows = (n_cats + cols - 1) // cols
                        
                        fig = make_subplots(rows=rows, cols=cols, 
                                          specs=[[{"type": "pie"}] * cols] * rows,
                                          subplot_titles=categories)
                        
                        for i, cat in enumerate(categories):
                            row = i // cols + 1
                            col = i % cols + 1
                            
                            values = group_df.loc[cat].values
                            labels = group_df.columns
                            
                            fig.add_trace(
                                go.Pie(labels=labels, values=values, name=cat,
                                      marker_colors=[mbti_colors.get(mbti, '#CCCCCC') for mbti in labels]),
                                row=row, col=col
                            )
                        
                        fig.update_layout(height=300 * rows, title_text=f"{group_col}ë³„ MBTI ë¶„í¬")
                        st.plotly_chart(fig, use_container_width=True)
                    
                    else:  # íˆíŠ¸ë§µ
                        fig = px.imshow(group_df, title=f"{group_col}ë³„ MBTI íˆíŠ¸ë§µ",
                                      aspect="auto", color_continuous_scale="Viridis")
                        fig.update_layout(height=400)
                        st.plotly_chart(fig, use_container_width=True)
                
                # í”¼ë²—í…Œì´ë¸”
                st.subheader("ğŸ“‹ ìƒì„¸ ë°ì´í„° í…Œì´ë¸”")
                pivot1 = pd.pivot_table(df, index=group_col, columns="mbti", aggfunc="size", fill_value=0)
                pivot2 = pd.pivot_table(df, index="mbti", columns=group_col, aggfunc="size", fill_value=0)
                
                col1, col2 = st.columns(2)
                with col1:
                    st.write("**ì„¸ë¡œ: ì§‘ë‹¨, ê°€ë¡œ: MBTI**")
                    st.dataframe(pivot1, use_container_width=True)
                with col2:
                    st.write("**ì„¸ë¡œ: MBTI, ê°€ë¡œ: ì§‘ë‹¨**")
                    st.dataframe(pivot2, use_container_width=True)
            
            with tab3:
                st.subheader(f"ğŸ¤– '{st.session_state.robot_id}'ì˜ MBTI ë³€í™” íˆìŠ¤í† ë¦¬")
                
                bot_records = df[(df['user_id']==USER_ID) & (df['robot_id']==st.session_state.robot_id)].sort_values("timestamp")
                
                if not bot_records.empty:
                    # ì¸í„°ë™í‹°ë¸” íƒ€ì„ë¼ì¸ ì°¨íŠ¸
                    bot_records['timestamp_short'] = pd.to_datetime(bot_records['timestamp']).dt.strftime("%Y-%m-%d")
                    
                    fig = px.scatter(bot_records, x='timestamp_short', y='mbti', 
                                   title=f"'{st.session_state.robot_id}' MBTI ë³€í™” íƒ€ì„ë¼ì¸",
                                   color='mbti', color_discrete_map=mbti_colors,
                                   size=[20] * len(bot_records))  # ëª¨ë“  ì ì„ ë™ì¼í•œ í¬ê¸°ë¡œ
                    
                    fig.update_layout(height=400, xaxis_title="ë‚ ì§œ", yaxis_title="MBTI ìœ í˜•")
                    fig.update_traces(marker=dict(size=15))
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # ë³€í™” ë¶„ì„
                    if len(bot_records) > 1:
                        # MBTI ë³€í™”ë¥¼ ë¬¸ìì—´ë¡œ ê³„ì‚°
                        mbti_list = bot_records['mbti'].tolist()
                        changes = []
                        for i in range(1, len(mbti_list)):
                            if mbti_list[i] != mbti_list[i-1]:
                                changes.append(f"{mbti_list[i-1]} â†’ {mbti_list[i]}")
                        
                        if changes:
                            st.info(f"ì´ {len(changes)}ë²ˆì˜ ë³€í™”ê°€ ìˆì—ˆìŠµë‹ˆë‹¤.")
                            
                            # ë³€í™” íŒ¨í„´ ë¶„ì„
                            change_counts = pd.Series(changes).value_counts()
                            if not change_counts.empty:
                                st.write("**ì£¼ìš” ë³€í™” íŒ¨í„´:**")
                                for change, count in change_counts.head(3).items():
                                    st.write(f"- {change}: {count}íšŒ")
                        else:
                            st.info("ë³€í™”ê°€ ì—†ì—ˆìŠµë‹ˆë‹¤.")
                    
                    # ìƒì„¸ ë°ì´í„°
                    st.dataframe(bot_records[["timestamp", "mbti", "gender", "age_group", "job"]], 
                               use_container_width=True)
                else:
                    st.info(f"ë¡œë´‡ '{st.session_state.robot_id}'ì˜ ì§„ë‹¨ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
            
            with tab4:
                st.subheader("ğŸ§  ê³ ê¸‰ ë¶„ì„")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("ğŸ“Š MBTI ìƒê´€ê´€ê³„ ë¶„ì„")
                    if len(df) > 1:
                        correlations = calculate_mbti_correlations(df)
                        if correlations is not None:
                            fig = px.imshow(correlations, 
                                          title="MBTI ìœ í˜• ê°„ ìƒê´€ê´€ê³„",
                                          color_continuous_scale="RdBu",
                                          aspect="auto")
                            fig.update_layout(height=400)
                            st.plotly_chart(fig, use_container_width=True)
                        else:
                            st.info("ìƒê´€ê´€ê³„ ë¶„ì„ì„ ìœ„í•œ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    
                    st.subheader("ğŸ¯ MBTI íŠ¸ë Œë“œ ì˜ˆì¸¡")
                    if len(df) > 0:
                        predicted_mbti, prediction_msg = predict_mbti_trends(df, USER_ID, st.session_state.robot_id)
                        if predicted_mbti:
                            st.success(f"ğŸ”® {prediction_msg}")
                        else:
                            st.info(prediction_msg)
                
                with col2:
                    st.subheader("ğŸŒ MBTI ë„¤íŠ¸ì›Œí¬ ë¶„ì„")
                    if len(df) > 1:
                        network, network_msg = create_mbti_network(df)
                        if network:
                            st.success(network_msg)
                            
                            # ë„¤íŠ¸ì›Œí¬ ì‹œê°í™”
                            pos = nx.spring_layout(network, k=1, iterations=50)
                            
                            # ë…¸ë“œì™€ ì—£ì§€ ë°ì´í„° ì¤€ë¹„
                            node_x = []
                            node_y = []
                            node_text = []
                            node_size = []
                            
                            for node in network.nodes():
                                x, y = pos[node]
                                node_x.append(x)
                                node_y.append(y)
                                node_text.append(node)
                                node_size.append(len([n for n in network.neighbors(node)]) * 10 + 10)
                            
                            edge_x = []
                            edge_y = []
                            edge_weights = []
                            
                            for edge in network.edges(data=True):
                                x0, y0 = pos[edge[0]]
                                x1, y1 = pos[edge[1]]
                                edge_x.extend([x0, x1, None])
                                edge_y.extend([y0, y1, None])
                                edge_weights.append(edge[2]['weight'])
                            
                            # ì—£ì§€ íŠ¸ë ˆì´ìŠ¤
                            edge_trace = go.Scatter(
                                x=edge_x, y=edge_y,
                                line=dict(width=2, color='#888'),
                                hoverinfo='none',
                                mode='lines')
                            
                            # ë…¸ë“œ íŠ¸ë ˆì´ìŠ¤
                            node_trace = go.Scatter(
                                x=node_x, y=node_y,
                                mode='markers+text',
                                hoverinfo='text',
                                text=node_text,
                                textposition="middle center",
                                marker=dict(
                                    size=node_size,
                                    color=[mbti_colors.get(mbti, '#CCCCCC') for mbti in node_text],
                                    line=dict(width=2, color='white')
                                ))
                            
                            fig = go.Figure(data=[edge_trace, node_trace],
                                          layout=go.Layout(
                                              title="MBTI ìœ í˜• ê°„ ê´€ê³„ ë„¤íŠ¸ì›Œí¬",
                                              showlegend=False,
                                              hovermode='closest',
                                              margin=dict(b=20,l=5,r=5,t=40),
                                              xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                                              yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))
                                          )
                            
                            fig.update_layout(height=400)
                            st.plotly_chart(fig, use_container_width=True)
                        else:
                            st.info(network_msg)
                    
                    st.subheader("ğŸ” ì‚¬ìš©ì í´ëŸ¬ìŠ¤í„°ë§")
                    if len(df) > 2:
                        clustered_df, cluster_msg = cluster_users_by_mbti(df)
                        if clustered_df is not None:
                            st.success(cluster_msg)
                            
                            # í´ëŸ¬ìŠ¤í„°ë³„ ë¶„í¬ ì‹œê°í™”
                            cluster_counts = clustered_df.groupby('cluster').size()
                            fig = px.bar(x=cluster_counts.index, y=cluster_counts.values,
                                        title="í´ëŸ¬ìŠ¤í„°ë³„ ì‚¬ìš©ì ë¶„í¬",
                                        labels={'x': 'í´ëŸ¬ìŠ¤í„°', 'y': 'ì‚¬ìš©ì ìˆ˜'})
                            fig.update_layout(height=300)
                            st.plotly_chart(fig, use_container_width=True)
                        else:
                            st.info(cluster_msg)
            
            with tab5:
                st.subheader("ğŸ¯ ê°œì¸ ëŒ€ì‹œë³´ë“œ")
                
                # ê°œì¸ ì§„í™” íƒ€ì„ë¼ì¸
                st.subheader("ğŸ“ˆ ë‚˜ì˜ MBTI ì§„í™” íƒ€ì„ë¼ì¸")
                my_all_records = df[df['user_id']==USER_ID].sort_values('timestamp')
                
                if not my_all_records.empty:
                    # ì¸í„°ë™í‹°ë¸” íƒ€ì„ë¼ì¸
                    my_all_records['timestamp_short'] = pd.to_datetime(my_all_records['timestamp']).dt.strftime("%Y-%m-%d")
                    
                    fig = px.scatter(my_all_records, x='timestamp_short', y='mbti', 
                                   color='robot_id', size=[20] * len(my_all_records),
                                   title="ë‚˜ì˜ ëª¨ë“  ë¡œë´‡ MBTI ë³€í™”",
                                   color_discrete_map=mbti_colors)
                    
                    fig.update_layout(height=400, xaxis_title="ë‚ ì§œ", yaxis_title="MBTI ìœ í˜•")
                    fig.update_traces(marker=dict(size=15))
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # ê°œì¸ í†µê³„
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("ì´ ì§„ë‹¨ ìˆ˜", len(my_all_records))
                    with col2:
                        st.metric("ì‚¬ìš©í•œ ë¡œë´‡ ìˆ˜", my_all_records['robot_id'].nunique())
                    with col3:
                        st.metric("MBTI ìœ í˜• ìˆ˜", my_all_records['mbti'].nunique())
                    with col4:
                        most_used_robot = my_all_records['robot_id'].mode().iloc[0] if not my_all_records['robot_id'].mode().empty else "N/A"
                        st.metric("ê°€ì¥ ë§ì´ ì‚¬ìš©í•œ ë¡œë´‡", most_used_robot)
                    
                    # MBTI ë³€í™” íˆíŠ¸ë§µ
                    st.subheader("ğŸ”¥ MBTI ë³€í™” íˆíŠ¸ë§µ")
                    mbti_pivot = my_all_records.pivot_table(index='robot_id', columns='mbti', aggfunc='size', fill_value=0)
                    
                    fig = px.imshow(mbti_pivot, 
                                  title="ë¡œë´‡ë³„ MBTI ë¶„í¬ íˆíŠ¸ë§µ",
                                  color_continuous_scale="Viridis",
                                  aspect="auto")
                    fig.update_layout(height=300)
                    st.plotly_chart(fig, use_container_width=True)
                    
                else:
                    st.info("ì•„ì§ ì§„ë‹¨ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤. ì²« ì§„ë‹¨ì„ ì‹œì‘í•´ë³´ì„¸ìš”!")
            
            with tab6:
                st.subheader("ğŸ¤– AI ì¸ì‚¬ì´íŠ¸")
                
                # AI ì¸ì‚¬ì´íŠ¸ ìƒì„±
                insights = generate_ai_insights(df, USER_ID, st.session_state.robot_id)
                
                if insights:
                    st.success("âœ¨ AIê°€ ë¶„ì„í•œ ì¸ì‚¬ì´íŠ¸")
                    
                    for insight in insights:
                        st.write(f"â€¢ {insight}")
                    
                    # ì¸ì‚¬ì´íŠ¸ ì‹œê°í™”
                    st.subheader("ğŸ“Š ì¸ì‚¬ì´íŠ¸ ì‹œê°í™”")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # ì—°ë ¹ëŒ€ë³„ MBTI ë¶„í¬
                        if 'age_group' in df.columns and len(df) > 0:
                            age_mbti = df.groupby(['age_group', 'mbti']).size().unstack(fill_value=0)
                            
                            fig = px.bar(age_mbti, title="ì—°ë ¹ëŒ€ë³„ MBTI ë¶„í¬",
                                       color_discrete_map=mbti_colors)
                            fig.update_layout(height=300)
                            st.plotly_chart(fig, use_container_width=True)
                    
                    with col2:
                        # ì„±ë³„ MBTI ë¶„í¬
                        if 'gender' in df.columns and len(df) > 0:
                            gender_mbti = df.groupby(['gender', 'mbti']).size().unstack(fill_value=0)
                            
                            fig = px.bar(gender_mbti, title="ì„±ë³„ MBTI ë¶„í¬",
                                       color_discrete_map=mbti_colors)
                            fig.update_layout(height=300)
                            st.plotly_chart(fig, use_container_width=True)
                    
                    # 3D ì°¨íŠ¸
                    st.subheader("ğŸŒ 3D MBTI ë¶„í¬ ë¶„ì„")
                    fig_3d, msg_3d = create_3d_mbti_chart(df)
                    if fig_3d:
                        st.plotly_chart(fig_3d, use_container_width=True)
                    else:
                        st.info(msg_3d)
                else:
                    st.info("AI ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ìˆëŠ” ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            with tab7:
                st.subheader("ğŸ“ˆ ì§„í–‰ë¥  ì¶”ì ")
            
            with tab7:
                st.subheader("ğŸ“‹ ë°ì´í„° ê´€ë¦¬")
                
                # ë‚´ ëª¨ë“  ë¡œë´‡ MBTI ì´ë ¥
                with st.expander("ë‚´ ëª¨ë“  ë¡œë´‡ MBTI ì§„ë‹¨/ë³€í™” ì´ë ¥", expanded=True):
                    my_records = df[df['user_id']==USER_ID].sort_values('timestamp')
                    if not my_records.empty:
                        # ì¸í„°ë™í‹°ë¸” í…Œì´ë¸”
                        st.dataframe(my_records[["timestamp", "robot_id", "mbti", "gender", "age_group", "job"]], 
                                   use_container_width=True)
                        
                        # ìš”ì•½ í†µê³„
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("ì´ ì§„ë‹¨ ìˆ˜", len(my_records))
                        with col2:
                            st.metric("ì‚¬ìš©í•œ ë¡œë´‡ ìˆ˜", my_records['robot_id'].nunique())
                        with col3:
                            st.metric("MBTI ìœ í˜• ìˆ˜", my_records['mbti'].nunique())
                    else:
                        st.info("ì•„ì§ ì§„ë‹¨ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
                
                # ë°ì´í„° ë‹¤ìš´ë¡œë“œ
                st.subheader("ğŸ“¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ")
                col1, col2 = st.columns(2)
                with col1:
                    st.download_button("ì „ì²´ ë°ì´í„° CSV", 
                                     df.to_csv(index=False).encode("utf-8"), 
                                     "all_responses.csv", "text/csv")
                with col2:
                    st.download_button("ì „ì²´ ë°ì´í„° JSON", 
                                     df.to_json(orient="records", force_ascii=False).encode("utf-8"), 
                                     "all_responses.json", "application/json")
                
                # HRI ëª¨ë¸ ì •ë³´
                if hri_models:
                    st.subheader("ğŸ¤– HRI ëª¨ë¸(ì‹œë‚˜ë¦¬ì˜¤) ëª©ë¡")
                    for m in hri_models:
                        st.markdown(f"**{m.get('name','ëª¨ë¸ëª… ì—†ìŒ')}**: {m.get('description','')}")
    
    except Exception as e:
        st.error(f"í†µê³„ ëŒ€ì‹œë³´ë“œ ì˜¤ë¥˜: {e}")
        st.exception(e)

    if st.button("ì§„ë‹¨ ì²«í™”ë©´ìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
        st.session_state.page = 1
        st.rerun()
st.markdown("---")
st.info("MBTI ê¸°ë°˜ ë¡œë´‡ ì„±ê²© ì§„ë‹¨íˆ´(ë¡œë´‡ID ì§ì ‘ì…ë ¥, ê·¸ë£¹/ë¡œë´‡ë³„ ë¶„ì„, ê³ ë„í™” ì‹œê°í™”)")